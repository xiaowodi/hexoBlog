
---
title: 2021年8月秋招复习笔记
---



# Java基础复习（JDK1.8）



## 容器篇

### 1.ArrayList

关键源码

```java
    /**
     * Default initial capacity.
     */
		// 默认初识容量为10
    private static final int DEFAULT_CAPACITY = 10;

    /**
     * Shared empty array instance used for empty instances.
     */
    private static final Object[] EMPTY_ELEMENTDATA = {};

    /**
     * Shared empty array instance used for default sized empty instances. We
     * distinguish this from EMPTY_ELEMENTDATA to know how much to inflate when
     * first element is added.
     */
    private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {};

    transient Object[] elementData; // non-private to simplify nested class access

		// 调用空参数构造方法之后，列表还是一个空的列表
    public ArrayList() {
        this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;
    }

	    /**
     * The maximum size of array to allocate.
     * Some VMs reserve some header words in an array.
     * Attempts to allocate larger arrays may result in
     * OutOfMemoryError: Requested array size exceeds VM limit
     */
		// 最大可库容的容量阈值， 当容量超过这个值的时候，ArrayList的最大容量为Integer.MAX_VALUE
    private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;

		// 添加元素
    public boolean add(E e) {
        ensureCapacityInternal(size + 1);  // Increments modCount!!
        elementData[size++] = e;
        return true;
    }
    private void ensureCapacityInternal(int minCapacity) {
        ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));
    }
    private static int calculateCapacity(Object[] elementData, int minCapacity) {
        if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) {
            return Math.max(DEFAULT_CAPACITY, minCapacity);
        }
        return minCapacity;
    }
    private void ensureExplicitCapacity(int minCapacity) {
        modCount++;

        // overflow-conscious code
        if (minCapacity - elementData.length > 0)
            grow(minCapacity);
    }
		// 扩容关键性代码
    private void grow(int minCapacity) {
        // overflow-conscious code
        int oldCapacity = elementData.length;
        int newCapacity = oldCapacity + (oldCapacity >> 1);  // 每次扩容为原来的1.5倍
        if (newCapacity - minCapacity < 0)
            newCapacity = minCapacity; //扩容后如果不够，那么就直接扩容为当前容量+1
        if (newCapacity - MAX_ARRAY_SIZE > 0)
            newCapacity = hugeCapacity(minCapacity);
        // minCapacity is usually close to size, so this is a win:
        elementData = Arrays.copyOf(elementData, newCapacity);  // 通过拷贝数据中的元素到新的数组，进行扩容
    }
		// 判断是否超过最大的扩容阈值
    private static int hugeCapacity(int minCapacity) {
        if (minCapacity < 0) // overflow
            throw new OutOfMemoryError();
        return (minCapacity > MAX_ARRAY_SIZE) ?
            Integer.MAX_VALUE :
            MAX_ARRAY_SIZE;
    }
```

**总结：**

- ArrayList底层是通过数组实现的
- ArrayList的默认容量为10；
- ArrayList为懒加载，只有在添加了第一个元素之后才会真正分配空间
- 扩容时，每次扩容为原来容量的1.5倍：原来的容量值+容量值>>1
- 如果扩容后容量超过Integer.MAX_VALUE-8，ArrayList的容量就为Integer的最大值
- 每次扩容时，是通过将旧的数组中的元素拷贝到扩容后的新的数组中
- 查询、更新元素效率高



### 2.LinkedList

- LinkedList底层是通过双向链表实现的
- 可以当成Stack与Queue来实现
- 插入，删除元素效率高



### 3.HashMap

[HashMap原理](https://editor.csdn.net/md/?articleId=113561579)

小总结：

- 初识主数组长度：16（1<<4）
- 主数组最大长度：2^30
- 默认的负载因子0.75
- 链表树化阈值1：8
- 链表树化阈值2：主数组table长度超过64
- 红黑树退化成链表阈值：树节点少于6

> HashMap的主数组长度需要满足2的幂次方
>
> 比如输入为1，table长度为2
>
> 输入长度为15，table长度为16

#### HashMap插入元素底层原理

1. 插入元素前对key的HashCode进行扰动函数hash()计算

   1. > 现获取key的hashCode的值h，然后将h与h的高16位进行异或运算
      >
      > 其目的是在进行路由寻址的时候，能够保证在元素个数较少的情况下，路由地址会同时保持高16位和低16位的共同特征

2. 插入元素

   1. > **路由公式： i=hash & (table.length - 1)**
      >
      > 为什么是table.length - 1，而不是table.length呢？
      >
      > 因为table.length为2的幂次方计算出来（1000000000），0多1少
      >
      > 直接与hash进行&运算的时候，都会变为0，更容易发生hash冲突
      >
      > -1的目的就是将众多的0变为1，*与运算之后的值更不容易相同，缓解hash冲突。*

   2. >路由地址计算出来后，就要插入元素
      >
      >**插入情景1**：主数组i位置为null（没有冲突），直接插入元素
      >
      >**插入情景2**：主数组i位置存在元素，且key值相同，就新的value值覆盖旧的value值
      >
      >**插入情景3**：主数组i位置存在元素，且没有树化，尾插法插入链表
      >
      >​                      如果链表长度超过8，同时主数组长度打到64， 才开始树化
      >
      >**插入情景4**：主数组i位置存在元素，且已经树化成红黑树，向红黑树中插入元素

3. 元素插入达到阈值，进行扩容

   1. > 阈值计算：当前主数组长度 * 负载因子

   2. 主数组每次扩容原来的一倍：通过向左移位来实现（避免经过乘法器，耗性能）

   3. 扩容情景：

      1. 主数组对应的slot内没有元素（null），不做处理

      2. 主数组对应的slot内有元素，但是没有链化，直接用改元素的扰动值hash直接与（新的数组长度-1）进行&运算，计算出新的位置

      3. 主数组对应的slot内有元素，但是已经链化了

         1. > 这时就需要进行高低链分链
            >
            > 用key的hash值（扰动后的）与扩容前的旧容量进行&运算，如果为0，即为低链；不为0,即为高链
            >
            > 低链的元素扩容后还在**原索引**位置；高链的元素扩容后在**原索引+旧容量**处

         2. 如果是红黑树进行分链的时候，可能元素会少于6个，这个时候就需要退化成链表

<font color=red>HashMap在高并发的情况下，链表会出现环形链表</font>

<font color=green>这里提及一道经典面试题：如何判断一个链表是否有环？？？</font>

使用快慢指针（double pointer）

slow和fast：slow每次走一步，fast每次走两步；如果两个指针能相遇，一定存在环儿；

（<font color=blue>生活中的例子：两个人跑圈，快的人在第二圈的时候一定会遇到慢的那个人</font>）

### 4.线程安全的容器

上述提及的容器类都是线程不安全的容器类，在并发环境下应该避免使用

#### 线程安全的List

```java
List list = new ArrayList<>(); // 效率高，不支持并发


List list = new Vector<>(); // 线程安全，但是效率低
/**
vector 在添加元素的一些操作的方法，添加了synchronized关键，进行上锁，效率比较低
*/

List list = Collections.synchronizedList(new ArrayList<>()); // 线程安全，小数量完全可以
/*
synchronizedList内部是通过在具体的操作上包裹synchronized关键字，而不是粗暴的同步整个方法

*/


List list = new CopyOnWriteArrayList<>(); // 线程安全，JUC包下的类（写时复制）,适用于多线程环境

/*
每次添加元素的时候，先将集合中的元素复制到一个长度+1的新的数组中，然后将新增的元素添加到新的数组中，然后再将数组引用指向新的数组中。

这就保证了：读和写是在不同的对象上进行的，所以不存在资源竞争关系，不需要加锁
					读写分离思想
*/
```

#### 线程安全的HashMap

```java
// Collections.synchronizedMap
Map<Object, Object> synchronizedMap = Collections.synchronizedMap(new HashMap<>());

// ConcurrentHashMap
ConcurrentHashMap<Object, Object> map = new ConcurrentHashMap<>();
```

##### ConCurrentHashMap

1.7 [ConCurrentHashMap小灰漫画](https://zhuanlan.zhihu.com/p/31614308)













## JVM篇

JVM：java虚拟机，能够识别.class文件，能够将class文件中的字节码指令进行识别并调用操作系统向上的API完成动作。

JRE：Java运行时环境。主要包括两个部分：JVM的标准实现和java的一些基本类库。相对于jvm来说，jre多出来一部分java类库

JDK：Java开发工具包。是整个Java开发的核心，继承了jre和一些好用的小工具。

### 1.JVM的内存构成

JAVA内存构成包括：**堆、java栈**、本地方法栈、程序计数器

jdk1.8之后，方法区（元空间并不在jvm中了，而是使用本地内存）

#### 1.1 程序计数器（PC寄存器）

##### 作用

- 字节码解释器通过改变程序计数器来一次读取指令，从而实现代码的流程控制
- 在多线程情况下，程序计数器记录的是当前线程执行的位置，从而当线程切换回来时，就知道上次执行到哪了。

##### 特点

- 是一块较小的内存空间
- 线程私有，每条线程都有自己的程序计数器
- 生命周期：随着线程的创建而创建，随着线程的结束而销毁
- 是唯一一个不会出现OutOfMemroyError的内存区域

#### 1.2 Java虚拟机栈（Java栈）

##### 定义

Java虚拟机栈是描述Java方法运行过程的内存模型

Java虚拟机栈会为每一个即将运行的Java方法创建一块叫做“栈帧”的区域，用于存放该方法运行过程中的一些信息，如：

- 局部变量表
- 操作数栈
- 动态链接
- 方法出口信息
- .......

![875223b19a3ea457678d5a09acb950e0](https://github.com/wangzhiwubigdata/God-Of-BigData/raw/master/JVM/JVM%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84.resources/6F3902DB-275A-4FC6-8E3A-754DE6F987BA.jpg)



##### 压栈出栈过程

当方法运行过程中需要创建局部变量时，就将局部变量的值存入栈帧中的局部变量表中。

Java虚拟机栈的栈顶的栈帧是当前正在执行的活动栈，也就是当前正在执行的方法，PC寄存器也会指向这个地址。只有这个活动的栈帧的本地变量可以被操作数栈使用，当在这个栈帧中调用另一个方法，与之对应的栈帧又会被创建，新创建的栈帧压入栈顶，变为当前的活动栈帧。

方法结束之后，当前栈帧被移除，栈帧的返回值变成新的活动栈帧中操作数栈的一个操作数。如果没有返回值，那么新的活动栈帧中操作数栈的操作数没有变化。

> 由于Java虚拟机栈是线程对应的，数据不是线程共享的，因此不同关系数据一致性问题，也不会存在同步锁的问题。

##### Java栈的特点

- 局部变量表随着栈帧的创建而创建，它的大小在编译时确定，创建时只需分配事先规定的大小即可。在方法运行过程中，局部变量表的大小不会发生改变。
- Java栈会出现两种异常：StackOverFlowError 和 OutOfMemoryError
  - StackOverFlowError若Java虚拟机栈的大小不允许动态扩展，那么当线程请求栈的深度超过当前Java虚拟机栈的最大深度时，抛出StackOverFlowError异常
  - OutOfMemoryError若允许动态扩展，那么当线程请求栈时内存用完了，无法再动态扩展时，抛出OutOfMemoryError异常。
- Java栈也是线程私有的，随着线程的创建而创建，随着线程的结束而销毁。

> 出现StackOverFlowError时，内存空间可能还有很多。

#### 1.3 本地方法栈（C栈）

##### 本地方法栈的定义：

本地方法栈是为JVM运行Native方法准备的空间，由于很多Native方法都是用C语言实现的，所以它通常又叫做C栈。它与Java虚拟机栈实现的功能类似，只不过本地方法栈是描述本地方法运行过程的内存模型。

##### 栈帧变化过程

本地方法被执行时，在本地方法栈也会创建一块栈帧，用于存放该方法的局部变量表、操作数栈、动态链接、方法出口信息等。

方法执行结束后，相应的栈帧也会出栈，并释放本地内存空间。也会抛出`StackOverFlowError`和`OutOfMemoryError`异常。

> 如果Java虚拟机本身不支持Native方法，或者本身不依赖与传统栈，那么可以不提供本地方法栈。如果本地支持方法栈，那么这个栈一般会在线程创建的时候按线程分配。

#### 1.4 Java堆Heap

##### 定义

堆是用来存放对象的内存空间，几乎所有的对象都存储在堆中

##### 特点

- 线程共享，整个Java虚拟机只有一个堆，所有的线程都访问同一个堆。而程序计数器、Java栈、本地方法栈都是一个线程对应一个。
- 在虚拟机启动时创建。
- 是垃圾回收的主要场所
- 进一步可分为：新生代（Eden区， From Survivor、To Survivor）、老年代

不同的区域存放不同生命周期的对象，这样可以根据不同的区域使用不同的垃圾回收算法，更具有针对性。

堆的大小既可以固定也可以扩展，但对于主流的虚拟机，堆的大小是可扩展的，因为当线程请求分配内存，但堆已满，且内存已无法再扩展时，就抛出`OutOfMemoryError`

> Java堆所使用的内存不需要保证是连续的。而由于堆是被所有线程共享的，所以对它的访问需要注意同步问题，方法和对应的属性都需要保证一致性。

##### 堆的划分

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200824152328561.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3Mjc2ODM1,size_16,color_FFFFFF,t_70#pic_center)

**逻辑上：**

- 新生代（Young）
  - Eden
  - 幸存区：From 和To
- 老年代（Old）
- 元空间

**物理上：**

物理上分为 **新生代+老年代**，而元空间使用的是直接内存

##### 内存分配策略

###### 1. 对象优先分配在Eden区

大多数情况下，对象在新生代Eden区中分配。当Eden去没有足够空间进行分配时，虚拟机将发起一次Minor GC。

👇**Minior GC vs Major GC**

- Minior GC：回收新生代（包括Eden和Survivor区域），因为Java对象大多都具备朝生夕灭的特性，所以Minior GC非常频繁，一般回收速度也比较快。
- Major GC：回收老年代，Major GC的速度一般会比Minor GC慢10倍以上。

###### 2.大对象直接进入老年代

大对象是指需要大量连续内存空间的Java对象，如很长的字符串或数据。

虚拟机提供了一个`-XX:PretenureSizeThreshold`参数，令大于这个设置值的对象直接在老年代分配，这样做的目的是避免在Eden以及两个Survivor区之间发生大量的内存复制。

> 只要分配的对象的内存大小大于这个参数的时候就会直接分配到老年代

###### 3. 长期存活的对象将进入老年代（默认15）

JVM给每个对象定义了一个对象年龄计数器。当新生代发生一次Minor GC后，存活下来的对象年龄+1，当年龄超过`-XX:MaxTenuringThreshold, 默认为15`设置的值时，就将超过该值的所有对象转移到老年代中。

###### 4. 动态年龄判定

Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半

（`-XX:TargetSurvivorRatio 默认值为50， 意味Survivor区对象使用率阈值为50%` ），年龄大于或等于该年龄的对象直接进入老年代。

##### 老年代空间分配担保

什么是空间分配担保？

> 在发生Minor GC之前，虚拟机会检查老年代最大可用的连续空间是否大于新生代所有对象的总空间：
>
> ​	如果大于，则此次Minor GC是安全的
>
> ​	如果小于, 则虚拟机会查看HandlePromotionFailure设置值是否允许担保失败。
>
> ​			如果`HandlePromotionFailure=true`，那么会继续检查老年代最大可用连续空间是否大于`历次晋升到老年代的对象的平均大小`，如果大于，则尝试进行一次Minor GC，但是这次Minor GC 依然是有风险的（<font color=green>因为Minor Gc之后，再次进入到老年代的对象的总大小有可能超过老年代最大可用连续空间</font>）
>
> ​			如果小于或者`HandlePromotionFailure=false`则改为进行一次Full GC

为什么要进行空间担保？

> 是因为新生代采用**复制收集算法**，假如大量对象在Minor GC后仍然存活（最极端情况为内存回收后新生代中所有对象均存活），而Survivor空间是比较小的，这时就需要老年代进行分配担保，把Survivor无法容纳的对象放到老年代。**老年代要进行空间分配担保，前提是老年代得有足够空间来容纳这些对象**，但一共有多少对象在内存回收后存活下来是不可预知的，**因此只好取之前每次垃圾回收后晋升到老年代的对象大小的平均值作为参考**。使用这个平均值与老年代剩余空间进行比较，来决定是否进行Full GC来让老年代腾出更多空间。

总结起来：新生代存在大量存活的对象，Survivor无法容纳这些对象，老年代要进行空间分配担保；担保前要判断自生有没有能力，如果没有能力就需要触发Full GC。

#### 1.5 方法区

##### 方法区定义

Java虚拟机规范中定义方法区是堆的一个逻辑部分。方法区存放一下信息：

- 已经被虚拟机加载的类信息
- 常量
- 静态变量
- 即时编译器编译后的代码

##### 方法区的特点

- 线程共享。方法区是堆的一个逻辑部分，因此和堆一样，都是线程共享的。整个虚拟机中只有一个方法区。
- 内存回收效率低。方法区中的信息一般需要长期存在，回收一遍之后可能只有少量信息无效。主要回收目标是：对常量池的回收；对类型的卸载

##### 运行时常量池

方法区中存放：**类信息、常量、静态变量、即时编译器编译后的代码**。常量就存放在运行时常量池中



### 2. 垃圾收集策略&算法

#### 2.1 判断对象是否存活

1. **引用计数法**

> 在对象头维护着一个counter计数器，对象被引用一次则计数器+1；若引用失效则计数器-1.当计数器为0时，就认为该对象无效了。
>
> 引用计数算法的实现简单，判定效率也很高，在大部分情况下它都是一个不错的算法。但是主流的 Java 虚拟机里没有选用引用计数算法来管理内存，主要是因为它很难解决对象之间循环引用的问题。
>
> > 举个栗子👉对象 objA 和 objB 都有字段 instance，令 objA.instance = objB 并且 objB.instance = objA，由于它们互相引用着对方，导致它们的引用计数都不为 0，于是引用计数算法无法通知 GC 收集器回收它们。

2. **可达性分析（GC Roots）**

基本思路就是通过一些列名为”GC Roots“的对象作为起始点，开始向下搜索，如果一个对象到GCRoots没有任何引用链，就说明这个对象已经没有引用了，就可以作为垃圾。

也即给定一个集合的引用作为根出发，通过引用关系遍历对象图，能被遍历到的（可达到的）对象就被判定为存活，没有被遍历到的就自然判定为死亡对象。

###### 哪些对象可以作为GC Roots

- 虚拟机栈中的引用的对象
- 方法区中的类静态属性引用的对象
- 方法区中的常量引用的对象
- synchronized同步的对象

GC Roots并不包括堆中对象引用的对象，这样就不会有循环引用的问题。



#### 2.1 垃圾收集算法

###### 标记-清除算法

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200824152623936.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3Mjc2ODM1,size_16,color_FFFFFF,t_70#pic_center)

缺点：内存会产生碎片化



###### 标记-复制

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200824152644220.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3Mjc2ODM1,size_16,color_FFFFFF,t_70#pic_center)

缺点：预留一半的内存区域；整个内存空间只有一半可以使用



###### 标记-整理

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200824152724174.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3Mjc2ODM1,size_16,color_FFFFFF,t_70#pic_center)

缺点：标记整理虽然可以解决内存碎片化问题，也不存在内存空间浪费，但是需要移动存活的对象，但是，当内存中存活对象多，并且都是一些微小对象，而且垃圾对象较少时，要移动大量的存活对象才能换取少量的内存空间。



###### 分代收集算法

一块独立的内存区域只能使用一种垃圾回收算法，根据对象生命周期特征，将其划分到不同的区域，再对特定区域使用特定的垃圾回收算法，只有这样才能将垃圾回收算法的优点发挥到极致，这种组合的垃圾回收算法称之为：分代收集算法（分代回收算法）

根据对象存活周期的不同，将内存划分为几块。一般是把 Java 堆分为新生代和老年代，针对各个年代的特点采用最适当的收集算法。

- 新生代：复制算法
- 老年代：标记-清除算法、标记-整理算法



### 3. HotSpot垃圾收集器（7种）

#### 3.1 新生代垃圾收集器

##### 1. Serial GC收集器

![1c13b8e41120caccd15369497355b588.png](https://img-blog.csdnimg.cn/img_convert/1c13b8e41120caccd15369497355b588.png)

> 单线程，只会使用一个cpu或一条线程去完成垃圾收集工作，这也意味着在进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束为止（<font color=red>臭名昭著的Stop The World</font>）
>
> **收集算法**：复制算法
>
> 与用户线程串行执行，单线程地好处就是减少上下文切换，减少系统资源的开销。但这种方式的缺点也很明显，在GC的过程中，会暂停程序的执行。若GC不是频繁发生，这或许是一个不错的选择，否则将会影响程序的执行性能。 对于新生代来说，区域比较小，停顿时间短，所以比较使用。
>
> **参数**：`-XX:+UseSerialGC` 
>
> 在JDK Client模式，不指定JVM参数，默认是串行垃圾收集器

##### 2. ParNew收集器

ParNew收集器是Serial GC的多线程版本，除了使用多线程进行垃圾收集外，其余行为包括Serial收集器可用的所有控制参数、收集算法(复制算法)、Stop The World、对象分配规则、回收策略等与Serial收集器完全相同，两者共用了相当多的代码。

![111fbad04e83f6fc486c78406621ae05.png](https://img-blog.csdnimg.cn/img_convert/111fbad04e83f6fc486c78406621ae05.png)

ParNew收集器除了使用了多线程收集外，其他与Serial收集器相比并无太多创新之外，但是它是许多运行在Server模式下的虚拟机首选的新生代收集器，其中有一个与性能无关的重要原因是，除了Serial收集器外，目前只有它能和CMS收集器配合工作。

> **算法**：复制算法
>
> 用于新生代
>
> GC时需要暂停所有用户线程，直到GC结束
>
> **参数**：
>
> ​	`-XX:+UseConcMarkSweepGC`：指定使用CMS后，会默认使用ParNew作为新生代收集器
>
> ​	`-XX:+UseParNewGC`：强制指定使用ParNew
>
> ​	`-XX:ParallelGCThreads`：指定垃圾收集的线程数量，ParNew默认开启的收集线程与CPU的数量相同

##### 3. Parallel Scavenge收集器（吞吐量优先）

Parallel收集器同样也采用了复制算法，并行回收和STW机制；和ParNew不同之处在于，Parallel收集器的目标则是达到一个可控制的吞吐量，也被称为吞吐量优先的垃圾收集器。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210128165345527.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3c3MzM1MTIz,size_16,color_FFFFFF,t_70)

> 参数：
>
> `-XX:MaxGCPauseMillis` 设置最大停顿时间STW，这参数设置的越小，停顿时间可能会缩短，但也会导致吞吐量下降，当值垃圾收集发生的更频繁。
>
> `-XX:GCtimeRatio` 垃圾收集时间占时间总比   用于衡量吞吐量
>
> ​	垃圾收集执行时间占应用程序执行时间的比例计算方法：`1/(n+1)`
>
> ​	例如`-XX:GCTimeRatio=19`,那么设置了垃圾收集时间占总时间的5% = 1/(19+1);
>
> ​	默认值是99，即1%；
>
> `-XX:UseAdaptiveSizePolicy` 设置Parallel收集器具有自适应调节功能；开启这个参数后，就不用手工指定一些细节参数了，如`新生代大小 -Xmn`、`Eden与Survivor区的比例 -XX:SurvivorRation`、`晋升老年代的对象年龄 -XX:MaxTenuringThreshold`

JVM会根据当前系统运行情况收集性能监控信息，动态调整这些参数，以提供最合适的停顿时间或最大的吞吐量，这种调节方式称为GC自适应的调节策略(GC Ergonomiscs)；

另外值得注意的一点是，Parallel Scavenge收集器无法与CMS收集器配合使用，所以在JDK 1.6推出Parallel Old之前，如果新生代选择Parallel Scavenge收集器，老年代只有Serial Old收集器能与之配合使用。



#### 3.2 老年代垃圾收集器

##### 1. Serial Old收集器

![abdedea73525f71775a338dbceeedd2a.png](https://img-blog.csdnimg.cn/img_convert/abdedea73525f71775a338dbceeedd2a.png)

> **算法**：标记-整理
>
> 可作为CMS收集器的后备预案，并在CMS发生”Concurrent Mode Failure“ 时使用。



##### 2. Parallel Old

![e1b908c08120b3323a3d5ca408bc569b.png](https://img-blog.csdnimg.cn/img_convert/e1b908c08120b3323a3d5ca408bc569b.png)

Parallel Scavenge收集器的老年代版本，并行收集器，吞吐量优先

> **算法**：标记-整理
>
> **参数**：`-XX:UseparallelOldGC` 指定使用Parallel Old收集器



##### 3. CMS并发清除（Concurrent Mark Sweep）

这个收集器有与工作线程执行**并发**的能力。

> **算法**：标记-清除
>
> **特点**：收集过程中不需要暂停用户线程，以获取最短回收停顿时间为目标

![ae5a11b458e117b8f30fdc064821647c.png](https://img-blog.csdnimg.cn/img_convert/ae5a11b458e117b8f30fdc064821647c.png)

CMS GC过程分四步：

1. **初始标记**（initial mark）

   > 单线程执行， 需要STW，但仅仅把GC Roots的直接关联可达的对象给标记一下，由于直接关联对象比较小，所以这里的速度非常快。

2. **并发标记**（Concurrent mark）

   > 对于初识标记过程所标记的初识标记对象，进行并发跟踪标记
   >
   > 此时其他线程仍可以继续工作。此处时间较长，但不停顿，并不能保证可以标记出所有的存活对象；

3. **重新标记**（remark）

   > 在并发标记的过程中，由于可能还会产生新的垃圾，所以此时需要重新标记新产生的垃圾。
   >
   > 此处执行**并行标记**，与用户线程不并发，所以依然是STW
   >
   > 且停顿时间比初识标记稍长，但远比并发标记短。

4. **并发清除**（Concurrent sweep）

   >  并发清除之前所有标记的垃圾；
   >
   > 其他用户线程仍可以工作，不需要停顿。

Tips：初始标记和并发标记仍然需要STW

**初始标记**仅仅标记一下GC Roots能直接关联到的对象，速度很快；

**并发标记**就是进行GC Roots Tracing的过程；

而**重新标记**阶段则是为了修正并发标记期间因用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段长，但远比并发标记的时间短。

由于整个过程中耗时最长的并发标记和并发清除过程，收集器线程都可以与用户线程一起工作，所以整体上说，CMS收集器的内存回收过程是与用户线程一共并发执行的。

> **参数**：
>
> `-XX:+UseConcMarkSweepGC`：使用CMS收集器
>
> `-XX:+UseCMSCompactAtFullCollection`：Full GC后，进行一次碎片整理；整理过程是独占的，会引起停顿时间变长。
>
> `-XX:+CMSFullGCsBeforeCompaction`：设置进行几次Full GC后，进行一次碎片整理
>
> `-XX:ParallelCMSThreads`：设置CMS的线程数量（一般情况约等于可用CPU数量）

**优点**：

总体来说，与Parallel Old垃圾收集器相比，CMS减少了执行老年代垃圾收集时应用暂停的时间；但却增加了新生代垃圾收集时应用暂停的时间，降低了吞吐量而且需要占用更大的堆空间；

由于耗时的**并发标记**和**并发清除**阶段都不需要暂停工作，所以整体的回收是低停顿的。

由于CMS以上特性，缺点也是比较明显的。

**缺点**：

1. 对CPU资源非常敏感

2. 浮动垃圾

   由于CMS并发清理阶段用户线程还在运行着，伴随程序运行自然就还会有新的垃圾不断产生，这一部分垃圾出现在标记过程之后，CMS无法在当次收集中处理掉它们，只好留待下一次GC时再清理掉。这一部分垃圾就称为“浮动垃圾”。

   由于在垃圾收集阶段用户线程还需要运行，那就还需要预留有足够的内存空间给用户线程使用，因此CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，也可以认为CMS所需要的空间比其他垃圾收集器大；

   `-XX:CMSInitiatingOccupancyFraction`: 设置CMS预留内存空间

3. ”Concurrent Mode Failure“失败

   如果如果CMS运行期间预留的内存无法满足程序需要，就会出现一次“Concurrent Mode Failure”失败，这时虚拟机将启动后备预案：临时启用Serial Old收集器来重新进行老年代的垃圾收集，这样会导致另一次Full GC的产生。这样停顿时间就更长了，代价会更大，所以 `-XX:CMSInitiatingOccupancyFraction`不能设置得太大。

4. 产生大量内存碎片

   这个问题并不是CMS的问题，而是算法的问题。由于CMS基于"标记-清除"算法，清除后不进行压缩操作，所以会产生碎片

   "标记-清除"算法介绍时曾说过：

   产生大量不连续的内存碎片会导致分配大内存对象时，无法找到足够的连续内存，从而需要提前触发另一次Full GC动作。

   **碎片解决方法：**

   -  `-XX:+UseCMSCompactAtFullCollection`

     - 使得CMS出现上面这种情况时不进行Full GC，而开启内存碎片的合并整理过程；但合并整理过程无法并发，停顿时间会变长；

   - `-XX:+CMSFullGCsBeforeCompation`

     - 设置执行多少次不压缩的Full GC后，来一次压缩整理

     - 为减少合并整理过程的停顿时间；

       默认为0，也就是说每次都执行Full GC，不会进行压缩整理；

       由于空间不再连续，CMS需要使用可用"空闲列表"内存分配方式，这比简单使用"碰撞指针"分配内存消耗大；

       

#### 3.3 G1收集器

G1(Garbage - First)名称的由来是G1跟踪各个Region里面的垃圾堆的价值大小(回收所获得的空间大小以及回收所需时间的经验值)，在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region。

注意：G1与前面的垃圾收集器有很大不同，它把新生代、老年代的划分取消了！

这样我们再也不用单独的空间对每个代进行设置了，不用担心每个代内存是否足够。

取而代之的是，G1算法将堆划分为若干个区域(Region)，它仍然属于分代收集器。不过，这些区域的一部分包含新生代，新生代的垃圾收集依然采用暂停所有应用线程的方式，将存活对象拷贝到老年代或者Survivor空间。老年代也分成很多区域，G1收集器通过将对象从一个区域复制到另外一个区域，完成了清理工作。这就意味着，在正常的处理过程中，G1完成了堆的压缩(至少是部分堆的压缩)，这样也就不会有CMS内存碎片问题的存在了。
![d278aed530716ea4981a02fb8590c946.png](https://img-blog.csdnimg.cn/img_convert/d278aed530716ea4981a02fb8590c946.png)



G1收集器运作过程

![b03dfc84f0de89fe474936cbd70aef32.png](https://img-blog.csdnimg.cn/img_convert/b03dfc84f0de89fe474936cbd70aef32.png)

1. 初识标记

   - 初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快

2. 并发标记

   - 进行GC Roots Tracing的过程，从刚才产生的集合中标记出存活对象；(也就是从GC Roots 开始对堆进行可达性分析，找出存活对象。)

     耗时较长，但应用程序也在运行；

     并不能保证可以标记出所有的存活对象；

3. 最终标记

   - 最终标记和CMS的重新标记阶段一样，也是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，

     这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短，

     也需要“Stop The World”。(修正Remebered Set)

4. 筛选回收

   - 首先排序各个Region的回收价值和成本
   - 然后根据用户期望的GC停顿时间来制定回收计划；
   - 最后按计划回收一些价值高的Region中垃圾对象

   回收时采用”复制算法“，从一个或多个Region复制存活对象到堆上的另一个空间Region，并且再次过程中压缩和释放内存；

   可以并发进行，降低停顿时间，并增加吞吐量

   > **参数**：
   >
   > `-XX:+UseG1GC`：指定使用G1收集器
   >
   > `-XX:InitiatingHeapOccupancyPercent`: 当整个Java堆的占用率达到参数值时，开始并发标记阶段；默认为45；
   >
   > `-XX:MaxGCPauseMillis`： 为G1设置暂停时间目标，默认值为200毫秒；
   >
   > `-XX:G1HeapRegionSize`：设置每个Region大小，范围1MB到32MB；目标是在最小Java堆时可以拥有约2048个

#### 小结：

![8d9b5b42d191a4ad452074f204507378.png](https://img-blog.csdnimg.cn/img_convert/8d9b5b42d191a4ad452074f204507378.png)







### 2.类加载过程

类从被加载到虚拟机内存中开始，到卸载出内存位置，他的整个生命周期如下如：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200810150148636.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2E2NDY3MDU4MTY=,size_16,color_FFFFFF,t_70)

1. **加载**
   - 通过一个类的全限定名来获取定义此类的二进制字节流
   - 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构
   - 在Java堆中生成一个代表这个类的java.lang.Class对象，作为方法区数据的访问入口
2. **验证**
   - 验证阶段作用是保证Class文件的字节流包含的信息是否符合JVM规范，不会给JVM造成危害。如果验证失败，就会抛出一个java.lang.VerifyError异常或子类异常。验证过程分为四个阶段：
     - 文件格式验证：验证字节流文件是否符合Class文件格式的规范，并且能被当前虚拟机正确的处理
     - 元数据验证：是对字节码描述的信息进行语义分析，以保证其描述信息符合Java语言的规范
     - 字节码验证：主要是进行数据流和控制流的分析，保证被校验类的方法在运行时不会危害JVM
     - 符号引用验证：符号引用验证发生在虚拟机将符号引用转化为直接引用的时候，这个转化动作将在解析阶段中发生。

<font color=green>符号引用（Symbolic References）说明</font>

> 符号引用以一组符号来描述所引用的目标，符号引用与虚拟机的内存布局无关，引用的目标不一定加载到内存中。
>
> <font color=blue>在java中，一个java类将会编译成一个class文件。在编译时，java类并不知道所引用的类的实际地址，因此只能使用符号引用来代替</font>
>
> 比如org.simple.People类引用了org.simple.Language类，在编译时People类并不知道Language类的实际内存地址，因此只能使用符号org.simple.Language（假设是这个，当然实际中是由类似于CONSTANT_Class_info的常量来表示的）来表示Language类的地址。各种虚拟机实现的内存布局可能有所不同，但是它们能接受的符号引用都是一致的，因为符号引用的字面量形式明确定义在Java虚拟机规范的Class文件格式中。

3. **准备**

   - 准备阶段为变量分配内存并设置类变量的初始化。在这个阶段分配的仅为类的变量（static修饰的变量），而不包括类的实例变量（实例变量在new 的时候初始化）。对已非final的变量，JVM会将其设置成”零值“，而不是其赋值语句的值：

     ```java
     private static int size = 12;
     ```

     那么这个阶段，size的值为0，而不是12。final修饰的类变量将会赋值成真实的值。

4. **解析**

   - 解析过程是将常量池内的符号引用替换成直接引用。主要包括四种类型引用的解析。**类或接口的解析**、**字段解析**、**方法解析**、**接口方法解析**。

5. **初始化**

   - 在准备阶段，类变量已经经过一次初始化了，在这个阶段，则是根据程序员通过程序制定的计划去初始化类的变量和其他资源。这些资源有static{}块，构造函数，父类的初始化等。

6. **使用**

7. **卸载**



### 3. 双亲委派机制



**java中的四种类加载器**

1. 启动（Bootstrap）类加载器

   > 启动类加载器是本地代码实现的类加载器，它负责将<JavaRuntimeHome>/lib下面的类库加载到内存中。由于启动类加载器涉及到虚拟机本地实现细节，开发者无法直接取到启动类加载器的引用。

2. 标准扩展（Extension）类加载器

   > 扩展类加载器负责将<JavaRuntimeHome>/lib/ext或者系统变量java.ext.dir指定位置中的类库加载到内存中。开发者可以直接使用标准扩展类加载器

3. 应用程序（Application）类加载器

   > 应用程序类加载器负责加载用户路径（classpath）上的类库





![在这里插入图片描述](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWcyMDIwLmNuYmxvZ3MuY29tL2Jsb2cvMjAwNDkzNC8yMDIwMDcvMjAwNDkzNC0yMDIwMDcyOTEyNDgyNjk0MC0xMDQyODAzODI0LnBuZw?x-oss-process=image/format,png#pic_center)

**双亲委派机制**

> 当一个类收到类加载请求时，它首先不会尝试自己去加载这个类，而是把这个请求委派给父类加载器去完成，每一层的类加载器都是如此，因此所有的加载请求都应该传送到启动类加载器中，只有当父类加载器反馈自己无法完成这个请求的时候（在它的加载路径下没有找到所需加载的Class）（从最顶层的BootStrap -》Extension-》Application-》自己定义的类加载器），子类加载器才会尝试自己加载。

**双亲委派机制的作用**

> 为了保证自己写的代码不污染java出厂自带的源代码。如果有人想替换系统级别的类：如String.java.篡改它的实现，但是在这种机制下这些系统的类已经被Bootstrap ClassLoader加载过了，所以并不会再去加载，从一定程度上防止了危险代码的植入。
>
> 1. 防止重复加载用一个.class。通过委托去上层，加载过了，就不用再加载一遍。保证数据安全
> 2. 保证了使用不同的类加载器最终得到的都是同一个Object对象。



### 3.创建（new）对象的过程

1. **检查类是否已经被加载**
   - 当JVM遇到一条字节码new指令时，首先检查该引用指向的类是否能够在常量池中被找到（也就是检查方法区中有没有该类的信息），如果没有，先加载这个类；有的话就执行下一步，为对象分配内存
2. **为对象分配内存空间**
   - 类加载检查通过后，接下来虚拟机会为对象分配内存。对象需要多大的内存在类加载完成后便可完全确定，为对象分配内存就是把一块确定大小的内存块从堆上划分出来。
3. **为对象字段设置零值**
   - 分配完内存后，需要对对象的字段进行零值初始化，（也就是对象的实例数据部分，对象的内存布局被分为三个部分：**对象头**、**实例数据**、**对齐填充**），对象头除外，零值初始化意思就是对对象的字段赋0值，或者null值。
4. **设置对象头**
   - 虚拟机需要对这个将要创建出来的对象，进行信息标记，包括是否为新生代/老年代，对象的hash码，元数据信息，这些标记存放在对象头信息中。
5. **执行构造方法**
   - 执行对象的构造方法，初始化对象，这样一个对象才算被成功创建。

### 4.对象的内存布局

> 提问：`Object o = new Object();` 请问一个object对象占多少内存空间？

Java对象的内存布局：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）。8字节对齐。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20201221191858529.png)

- Mark Word
  - 存储对象的hashCode、GC分代年龄、锁状态标志、线程只有的锁、偏向线程ID、偏向时间戳
- Class Pointer
  - 指向对象对应的Class对象（类对象）的内存地址
- Instance Date
  - 具体的数据大小，如对象含有一个int成员变量，即为4字节

在64bit的JVM中，MarkWord为64bit-8字节，这样一个`Object`对象占有**16个字节**



### 5. 四大引用类型



#### 1. 强引用

`StrongReference`是java的默认引用形式，使用时不需要显示定义。任何通过强引用所使用的对象，不管jvm内存是否充足，Java GC都不会主动回收具有强引用的对象。

> 如果一个对象具有强引用，那么垃圾收集器不会回收它
>
> 当JVM内存空间不足时，Java虚拟机宁愿抛出OurOfMemoryError错误，使程序异常终止，也不会回收强引用对象。

#### 2. 软引用

`SoftReference<String[]> softArr = new SoftReference<String[]>(new String[] {"a", "b", "c"});`

软引用在内存充足时，GC不会回收；如果内存不足时，GC会回收这个对象。

**应用场景**

> 实现内存敏感的高速缓存，比如网页缓存，图片缓存等。使用软引用能防止内存泄漏



#### 3. 弱引用

`WeakReference<String[]> weakArr=new WeakReference<String[]>(new String[]{"a","b","c"});`

如果一个对象只具有弱引用，无论内存充足与否，Java GC后对象都会被回收。

**应用场景**

> ThreadLocal

##### ThreadLocal 弱引用造成的数据泄漏问题

`ThreadLocalMap`内部Entry类

```java
static class Entry extends WeakReference<ThreadLocal<?>> {
  /** The value associated with this ThreadLocal. */
  Object value;

  Entry(ThreadLocal<?> k, Object v) {
    super(k);
    value = v;
  }
}
```

可以看出，ThreadLocal内部每个线程维护的本地变量map中的Entry的key是弱引用类型`WeakReference`, 不管JVM内存空间是否充足，在GC的时候，都会回收里面的key。

<font color=red>但是value依然是强引用类型</font>，这就会造成这种情况：GC回收的时候，把key进行了回收，变为了`null`,但是其对应的value还有值存在，但是无法被引用到了，这就造成了`内存泄漏`,因此，在实际使用ThreadLocal的过程中，使用完毕后需要及时调用`remove()`方法，避免造成数据泄漏。



#### 4. 虚引用

虚引用需要配合引用队列`ReferenceQueue`联合使用。当执行Java GC时如果一个对象只有虚引用，就会把这个对象加入到与之关联的`ReferenceQueue`中。

```java
//虚引用PhantomReference
    //必须和引用队列联合使用
    ReferenceQueue<String[]> rqueue = new ReferenceQueue<>();
    PhantomReference<String[]> phanArr = new PhantomReference<String[]>(new String[]{"a","b"},rqueue);
    /**
     *
     * 应用场景：
     *大多被用于引用销毁前的处理工作
     *
     */
```

当垃圾回收期准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。

程序可以通过判断引用队列中是否已经加入了虚引用，来了解引用的对象是否将要被垃圾回收。程序如果发现某个虚引用已经被加入到引用队列中，那么就可以在所引用的对象的内存被回收之前采取必要的行动。



### 6. JVM常用调优参数

[Oracle关于JVM参数配置参考表](https://www.oracle.com/java/technologies/javase/vmoptions-jsp.html)

| 配置参数                             | 功能                                                         | 备注 |
| ------------------------------------ | ------------------------------------------------------------ | ---- |
| `-Xms`                               | 初识堆大小。如`-Xms256m`                                     |      |
| `-Xmx`                               | 最大堆大小。如`-Xmx1024m`                                    |      |
| `-Xmn`                               | 新生代大小。通常为`Xmx`的1/3或1/4.<br />新生代=Eden+2个Survivor空间。<br />实际可用空间为=Eden+1个Survivor，即90% |      |
| `-Xss`                               | 每个线程堆栈大小，默认为1M                                   |      |
| `-XX:NewRatio`                       | 老年代/新生代的比例，默认`-XX:NewRatio=2`,代表老年代：新生代=2：1 |      |
| `-XX:SurvivorRatio`                  | 新生代中Eden与Survivor的比值。默认值为8  `-XX:SurvivorRatio=8` |      |
| `java -XX:+PrintFlagsFinal -version` | 查看jvm所有参数选项的值                                      |      |
| `-XX:MaxTenuringThreshold`           | 新生代晋升老年的的年龄<br />默认值`-XX:MaxTenuringThreshold=15` |      |
| `-XX:MetaspaceSize`                  | 元空间大小                                                   |      |
| `-XX:MaxMetaspaceSize`               | 元空间最大空间大小                                           |      |
| `-XX:PretenureSizeThreshold`         | 大对象所占空间超过这个阈值，直接分配到老年代                 |      |
| `-XX:+PrintGCDetails`                | 打印GC信息                                                   |      |
| `关于设置垃圾收集器`                 |                                                              |      |
| `-XX:+UseSerialGC`                   | 新生代使用Serial GC， 老年代使用Serial old                   |      |
| `-XX:+UseParNewGC`                   | 新生代使用ParNew收集器，老年代使用Serial Old                 |      |
| `-XX:+UseConcMarkSweepGC`            | 新生代使用ParNew收集器，老年代使用CMS                        |      |
| `-XX:ParallelGCThreads=8`            | 这个参数指定并行GC线程的数量，<br />一般最好和cpu核心数相当。 |      |
| `-XX:+UseParallelOldGC`              | 新生代使用ParallelGC收集器，<br />老年代使用ParallelOldGC收集器 |      |
| `-XX:ConcGCThreads`                  | 设置CMS并发线程数                                            |      |
| `-XX:+UseG1GC`                       | 开启G1收集器                                                 |      |
| `关于锁`                             |                                                              |      |
| `-XX:+UseSpinning`                   | 启用自旋锁优化，jdk1.6之后默认开启                           |      |
| `-XX:PreBlockSpin`                   | 设置自旋多少次后升级为重量级锁；默认`-XX:PreBlockSpin=10`    |      |
|                                      |                                                              |      |





## 并发与多线程篇

### 1. 进程与线程

进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。同时，每个进程还占有某些系统资源如CPU时间，内存空间，文件，输入输出设备的使用权等等。

**进程与进程之间的通信方式**

1. 管道pipe
   - 通常指无名管道，unix系统IPC最古老的形式
   - 只能用于具有亲缘关系的进程之间的通信（父子进程，兄弟进程）
2. 命名管道FIFO
   - 在磁盘上有对应的节点，但是没有数据块。一旦建立，任何进程都可以通过文件名将其打开和进行读写，而不局限于父子进程，当然前提是进程对FIFO有适当的访问权。当不再被进程使用时，FIFO在内存中释放，但磁盘节点仍然存在。
3. 消息队列MessageQueue
   - 消息队列，就是一个消息的链表，是一系列保存在内核中消息的列表。用户进程可以向消息队列添加消息，也可以从消息队列读取消息。
   - 消息队列与管道通信相比，其优势是对每个消息指定特定的消息类型，接收的时候不需要按照队列次序，而是可以根据自定义条件接收特定类型的消息。
   - 进程间通过消息队列通信，主要是：创建或打开消息队列，添加消息，读取消息和控制消息队列
4. 共享存储SharedMemory
   - 共享内存允许两个或多个进程共享一个给定的存储区，这一段存储区可以被两个或两个以上的进程映射至自身的地址空间中，一个进程写入共享内存的信息，可以被其他使用这个共享内存的进程，通过一个简单的内存读取策略读出，从而实现了进程间的通信。
   - 采用共享内存进行通信的一个主要好处是**效率高**，因为进程可以直接读写内存，而不需要任何数据的拷贝，对于像管道和消息队列等通信方式，则需要在内核和用户空间进行四次的数据拷贝，而共享内存则只拷贝两次：` 一次从输入文件到共享内存`和 `一次从共享内存输出文件`
5. 信号量Semaphore
   - 信号量用于实现进程间的互斥与同步，而不是用于存储进程间通信数据。
6. 套接字Socket
   - 适合同一主机的不同进程间和不同主机的进程间进行全双工网络通信
7. 信号（sinal）



#### 线程的几种状态

`Thread.State`枚举类查看线程的各种状态

1. NEW（新建）
2. RUNNABLE（就绪）
3. BLOCKED（阻塞）
4. WAITING（等待）
5. TIMED_WAITING（超时等待）
6. TERMINATED（终止）



**wait/sleep都会导致线程的阻塞，有什么区别？**

- wait放开手去睡，放开手里的锁
- sleep握紧手去睡，醒了手里还有锁



#### Java中实现多线的方式

1. 继承Thread类，实现run方法
2. 实现Runnable接口，实现run方法
3. 实现Callable接口，实现call方法。注意：新建Thread的时候，Thread的构造方法中没有接收Callable的。（中间商赚差价！！！）所有我们需要找到一个既可以联系Runnable接口又联系Callable接口的类（FutureTask））
   - `FutureTask`中的`get()`方法会阻塞线程，一直等待线程计算完成后才执行下面的后续代码。一般放在最后。
   - 同一个futureTask对象只能被线程调用一次，当有新的线程调用了已经被调用过的futuretask对象时，这次只会复用上一次的结果，不会再执行一次。
4. 线程池`ExecutorService`(ThreadPoolExecutor类)





### 2. JUC

#### JUC强大的辅助类：

##### 1. CountDownLatch类

计数器不为0，`countDownLatch.await(); `方法后面的代码都被一直阻塞

每调用一个线程，就需要执行`countDownLatch.countDown()`,将其计数器减一

##### 2. CyclicBarrier

一句话：集齐七颗龙，召唤神龙。

没调用一个线程，就需要执行`cyclicBarrier.await()`,将计数器加1

**CyclicBarrier类与CountDownLatch类的区别**

| CountDownLatch                                               | CyclicBarrier                                                |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| 减计数方式                                                   | 加计数方式                                                   |
| 计算为0时释放所有等待的线程                                  | 计数达到指定值时释放所有等待线程                             |
| 计数为0时，无法重置                                          | 计数达到指定值时，计数置为0重新开始                          |
| 调用countDown()方法计数减一，调用await()方法只进行阻塞，对计数没任何影响 | 调用await()方法计数加1，若加1后的值不等于构造方法的值，则线程阻塞 |
| 不可重复利用                                                 | 可重复利用                                                   |

##### 信号量：Semaphore类（类似于PV操作）

两个关键性操作：

1. `semaphore.acquire()` 请求资源
2. `semaphore.release() ` 释放资源

> acquire：当一个线程调用acquire操作时，它要么成功，获取信号量（信号量-1）；要么一直等待下去，直到有线程释放了信号量，或者超时
>
> release：实际上会将信号量的值加1，然后唤醒等待的线程。

信号量的主要作用：

> 用于**对多个共享资源的互斥使用**
>
> 用于**并发线程数的控制**



### 阻塞队列（BlockingQueue）

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200823081540511.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3Mjc2ODM1,size_16,color_FFFFFF,t_70#pic_center)

线程1往阻塞队列中生产元素，线程2 从阻塞队列中消费元素。

阻塞队列满了，生产线程阻塞；

阻塞队列空了，消费线程阻塞。

***阻塞队列的用处***

> 在多线程领域：所谓阻塞，在某些情况下会 挂起 线程（即阻塞），一旦满足条件，被挂起的线程又会被自动唤醒。
> 为什么需要BlockingQueue，好处是我们不需要关心什么时候 需要阻塞线程，什么时候需要唤醒线程因为这一切BlockingQueue都给你一手包办了



| 实现类                                     | 说明                                                         |
| ------------------------------------------ | ------------------------------------------------------------ |
| <font color=red>ArrayBlockingQueue</font>  | 由数组结构组成的有界阻塞队列                                 |
| <font color=red>LinkedBlockingQueue</font> | 由链表结构组成的有界（但大小默认值为integer.MAX_VALUE）阻塞队列 |
| <font color=red>SynchrousQueue</font>      | 不存储元素的阻塞队列，也即单个元素的阻塞队列                 |
| PriorityBlockingQueue                      | 支持优先级排序的无界阻塞队列                                 |
| DelayQueue                                 | 使用优先级队列实现的延迟无界阻塞队列                         |
| LinkedTransferQueue                        | 由链表组成的无界阻塞队列                                     |
| LinkedBlockingDeque                        | 由链表组成的双向阻塞队列                                     |





### 3. 线程池

```java
public ThreadPoolExecutor(
  												// 常驻核心线程数
  												int corePoolSize,
  												// 最大线程数
                          int maximumPoolSize,
  												// 空闲线程的存活时间，
                          long keepAliveTime,
  												// 时间单位
                          TimeUnit unit,
  												// 阻塞队列：用于存放被提交但尚未被执行的任务，类似于银行的候客区：窗口已经满了，需要排队等待
                          BlockingQueue<Runnable> workQueue,
  												// 线程池中工作线程的线程工厂，用于创建线程。
                          ThreadFactory threadFactory,
  												// 拒绝策略（阻塞队列满了，无法再容纳更多的线程任务）
                          RejectedExecutionHandler handler) {
  if (corePoolSize < 0 ||
      maximumPoolSize <= 0 ||
      maximumPoolSize < corePoolSize ||
      keepAliveTime < 0)
    throw new IllegalArgumentException();
  if (workQueue == null || threadFactory == null || handler == null)
    throw new NullPointerException();
  this.acc = System.getSecurityManager() == null ?
    null :
  AccessController.getContext();
  this.corePoolSize = corePoolSize;
  this.maximumPoolSize = maximumPoolSize;
  this.workQueue = workQueue;
  this.keepAliveTime = unit.toNanos(keepAliveTime);
  this.threadFactory = threadFactory;
  this.handler = handler;
}
```



#### 线程池拒绝策略

| 拒绝策略                                 | 说明                                                         | 备注 |
| ---------------------------------------- | ------------------------------------------------------------ | ---- |
| `ThreadPoolExecutor.AbortPolicy(默认)`   | 直接抛出RejectedExecutionException异常阻止系统正常运行       |      |
| `ThreadPoolExecutor.CallerRunsPolicy`    | **调用者运行**机制：该策略既不会抛弃任务，也不会抛出异常，而是将某些任务回退到调用者，从而降低新任务的流量（谁让你找我的，你回去找谁去） |      |
| `ThreadPoolExecutor.DiscardOldestPolicy` | 抛弃队列中等待最久的任务，然后把当前任务加入队列中尝试再次提交当前任务。 |      |
| `ThreadPoolExecutor.DiscardPolicy`       | 该策略默默地丢弃无法处理的任务，不予任何处理也不抛出异常。如果任务允许丢失，这是最好的一种策略。 |      |





### 4. volatile&JMM内存模型



#### JMM内存模型

<img src="https://img-blog.csdnimg.cn/20200824153251847.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3Mjc2ODM1,size_16,color_FFFFFF,t_70#pic_center#" alt="在这里插入图片描述" style="zoom:50%;" />

> JMM是java的内存模型，JMM定义了程序中各个共享变量的访问规则，即在虚拟机中奖变量存储到内存和从内存读取变量这样的底层细节。
>
> 设计JMM主要的目的是：屏蔽各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。
>
> 由于JVM运行程序的实体是线程，而每个线程创建时JVM都会为其创建一个工作内存（有些地方成为栈空间），工作内存是每个线程私有的数据区域，而Java内存模型中规定所有变量都存储在主存中，主存是共享内存区域，所有线程都可以访问。
>
> 但是线程对变量的操作（读取赋值等）必须在工作内存中进行，首先要将变量先从主存拷贝到线程自己的工作内存空间，然后对变量进行操作，操作完成后再将变量写回主存。
>
> 不能直接操作主存中的变量，各个线程中的工作内存中存储着主存中的变量副本，因此不同线程间无法访问对方的工作内存，线程间的通信（传值）必须通过主存来完成。



#### volatile

##### volatile特性：

1. **可见性**

   - 保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的

   - > **volatile底层实现可见性的原理**
     >
     > 以两核CPU为例（双核）
     >
     > 由于cpu的速度要比内存快的多，为了弥补这个性能差异，cpu内核都会有自己的高速缓冲区，当内核运行线程执行一段代码时，首先将这段代码的指令集进行缓存行填充到高速缓存，如果非volatile变量，当CPU执行修改了此变量之后，会将修改后的值回写到高速缓存，然后再刷新到内存中。如果刷新回内存之前，由于是共享变量，那么core2中的线程执行的代码也用到了这个变量，这时变量的值依然是旧的。
     >
     > volatile关键字就会解决这个问题
     >
     > > 首先被volatile关键字修饰的共享变量在转换成汇编语言时，会加上一个lock为前缀的指令，当cpu发现这个指令时，立即做两件事：
     > >
     > > 1. <font color=green>将当前内核高速缓存行的数据立刻回写到内存；</font>
     > > 2. <font color=green>使其他内核里缓存了该内存地址的高速缓存中的数据无效。重写从主存中读取该数据</font>

2. **禁止指令重排**

   - volatile内存区的读写，通过加屏障来禁止指令重排列
   - LoadLoad屏障：对于这样的语句`Load1; LoadLoad; Load2`, 在`Load2`以及后续读取操作要读取的数据被访问前，要保证`Load1`要读取的数据被读取完毕。
   - StoreStore屏障：对于这样的语句`Store1;StoreStore;Store2`, 在`Store2`以及后续写入操作执行前，保证`Store1`的写入操作对其它处理器可见。
   - LoadStore屏障：对于这样的语句`Load1;LoadStore;Store2`,在`Store2`以及后续写入操作被刷出前，保证`Load1`要读取的数据被读取完毕
   - StoreLoad屏障：对于这样的语句`Store1;StoreLoad;Load2`,在`Load2`以及后续所有读取操作执行前，保证`Store1`的写入对所有处理器可见。

3. **不保证原子性**



### 5. synchronized原理

[深入分析Synchronized原理](https://www.cnblogs.com/aspirant/p/11470858.html)

```java
public class SynchronizedDemo {

    public synchronized void method(){
        synchronized (this){
            System.out.println(
                    "Synchronized Demo"
            );
        }
    }

    public static void main(String[] args) {
    }
}
```

上述代码通过 `javap -c -l -p .class`反编译成字节码结果如下：

``` java
Compiled from "SynchronizedDemo.java"
public class SynchronizedDemo {
  public SynchronizedDemo();
    descriptor: ()V
    Code:
       0: aload_0
       1: invokespecial #1                  // Method java/lang/Object."<init>":()V
       4: return
    LineNumberTable:
      line 1: 0
    LocalVariableTable:
      Start  Length  Slot  Name   Signature
          0       5     0  this   LSynchronizedDemo;

  public synchronized void method();
    descriptor: ()V
    Code:
       0: aload_0
       1: dup
       2: astore_1
       3: monitorenter			// 一次 monitorenter
       4: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;
       7: ldc           #3                  // String Synchronized Demo
       9: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V
      12: aload_1
      13: monitorexit			// 两次monitorexit
      14: goto          22
      17: astore_2
      18: aload_1	
      19: monitorexit			// 两次monitorexit
      20: aload_2
      21: athrow
      22: return
    Exception table:
       from    to  target type
           4    14    17   any
          17    20    17   any
    LineNumberTable:
      line 4: 0
      line 5: 4
      line 8: 12
      line 9: 22
    LocalVariableTable:
      Start  Length  Slot  Name   Signature
          0      23     0  this   LSynchronizedDemo;

  public static void main(java.lang.String[]);
    descriptor: ([Ljava/lang/String;)V
    Code:
       0: return
    LineNumberTable:
      line 12: 0
    LocalVariableTable:
      Start  Length  Slot  Name   Signature
          0       1     0  args   [Ljava/lang/String;
}

```

1. `monitorenter`：每个对象都是一个监视器锁（**monitor**）。当**monitor**被占用时就会处于锁定状态，线程执行`monitorenter`指令时，尝试获取**monitor**的所有权，过程如下：

> 1. 如果**monitor**的进入数为0，则该线程进入**monitor**，然后将进入数设置为1，该线程即为**monitor**的所有者；
> 2. 如果线程已经占有该**monitor**，只是重新进入，则进入**monitor**的进入数加1；
> 3. 如果其他线程已经占用了**monitor**，则该线程进入阻塞状态，知道**monitor**的进入数为0，再重新尝试获取**monitor**的所有权

2. `monitorexit`:执行`monitorexit`的线程必须是`objectref`所对应的`monitor`的所有者。指令执行时，`monitor`的进入数减1，如果减1后进入数为0，那线程退出`monitor`，不再是这个`monitor`的所有者。其他被这个`monitor`阻塞的线程可以尝试去获取这个`monitor`的所有权

> monitorexit指令出现了两次，第1次为同步正常退出释放锁；第2次为发生异常退出释放锁；

**Synchronized**的语义底层是通过一个monitor的对象来完成的。





### 6.锁&锁升级

[浅谈偏向锁、轻量级锁、重量级锁](https://www.jianshu.com/p/36eedeb3f912)

Synchronized加锁时，进程会从**用户态**转换成**内核态**，让操作系统帮忙调度。用户态与内核态的转换是非常耗时的，所以说Synchronized是重要级的锁。

**关于Synchronized的升级**

参考文献https://blog.csdn.net/steven2xupt/article/details/108047270

由于synchronized性能问题在JDK1.6前饱受诟病，同时和@author Doug Lea大神写的目前在JUC下的AQS实现的锁差距太大，synchronized开发人员感觉脸上挂不住，所以在1.6版本进行了大幅改造升级，于是就出现了现在常通说的锁升级或锁膨胀的概念,整体思路就是能不打扰操作系统大哥就不打扰大哥，能在用户态解决的就不经过内核。

![img](https://img-blog.csdnimg.cn/2020081722362322.png?type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3N0ZXZlbjJ4dXB0,size_16,color_FFFFFF,t_70#pic_center)

**升级过程**

1. 无锁态
2. 偏向锁
3. 轻量级锁（自旋锁：CAS）
4. 重量级锁



**MarkWord**

![img](https://img-blog.csdnimg.cn/20200817001540364.png?type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3N0ZXZlbjJ4dXB0,size_16,color_FFFFFF,t_70#pic_center)

简单来说：

| 状态       | 标志位 | 存储内容                             |
| ---------- | ------ | ------------------------------------ |
| 未锁定     | 01     | 对象哈希码、对象分代年龄             |
| 轻量级锁定 | 00     | 指向锁记录的指针                     |
| 重量级锁定 | 10     | 执行重量级锁定的指针                 |
| GC标记     | 11     | 空(不需要记录信息)                   |
| 偏向锁     | 01     | 偏向线程ID、偏向时间戳、对象分代年龄 |



![img](https://upload-images.jianshu.io/upload_images/4491294-e3bcefb2bacea224.png)



对象内存布局中的markWord会记录当前只有锁的线程id，如果一个线程获取到锁，那么这个线程线程的id会被记录到markword中。

**锁升级的大致过程：**

> 从**无锁态**，如果有对象尝试获取锁，则进入**偏向锁转态**（这时只有一个线程在使用资源）；
>
> 如果一次还是这个线程使用资源，（尝试获取锁），先会比较markword中的线程id是否为这个线程，如果是，直接获得**偏向锁**。
>
> 如果有竞争（就是不同线程争抢锁），就会升级到轻量级锁（自旋锁CAS）；
>
> 如果竞争激烈，自旋了好久（**默认10次**）都没有竞争到锁，那么就会升级为**重量级锁**，然后**挂起此线程**，等待资源的释放后**重新竞争锁**

>  JDK1.6引入了自适应自旋锁，所谓自适应自旋锁，就意味着自旋的次数不再是固定的，具体规则如下：
>
> 自旋次数通常由前一次在同一个锁上的自旋时间及锁的拥有者的状态决定。如果线程【T1】自旋成功，自旋次数为17次，那么等到下一个线程【T2】自旋时，也会默认认为【T2】自旋17次成功，
>
> 如果【T2】自旋了5次就成功了，那么此时这个自旋次数就会缩减到5次。
>
> 自适应自旋锁随着程序运行和性能监控信息，从而使得虚拟机可以预判出每个线程大约需要的自旋次数





### 7.AQS（AbstractQueuedSynchronizer）：抽象队列同步器

#### CLH锁

AQS是JUC的核心，而CLH锁又是AQS的基础，说核心也不为过，因为AQS就是用了变种的CLH锁。如果要学好Java并发编程，那么必定要学好JUC；学好JUC，必定要先学好AQS；学好AQS，那么必定先学好CLH。因此，这就是我们为什么要学习CLH锁的原因。







## 常用设计模式



### 1.单例模式







### 2.工厂模式







### 3.模板模式







### 4.代理模式



```java
public class ProxyTest {
    public static void main(String[] args) {
        Proxy proxy = new Proxy();
        proxy.Request();
    }
}
//抽象主题
interface Subject {
    void Request();
}
//真实主题
class RealSubject implements Subject {
    public void Request() {
        System.out.println("访问真实主题方法...");
    }
}
//代理
class Proxy implements Subject {
    private RealSubject realSubject;
    public void Request() {
        if (realSubject == null) {
            realSubject = new RealSubject();
        }
        preRequest();
        realSubject.Request();
        postRequest();
    }
    public void preRequest() {
        System.out.println("访问真实主题之前的预处理。");
    }
    public void postRequest() {
        System.out.println("访问真实主题之后的后续处理。");
    }
}
```





### 5.建造者模式









### 6.观察者模式





### 7. 原型设计模式



原型（Prototype）模式的定义如下：用一个已经创建的实例作为原型，通过复制该原型对象来创建一个和原型相同或相似的新对象。在这里，原型实例指定了要创建的对象的种类。用这种方式创建对象非常高效，根本无须知道对象创建的细节。例如，Windows 操作系统的安装通常较耗时，如果复制就快了很多。在生活中复制的例子非常多，这里不一一列举了。

#### 原型模式的优点：

- [Java](http://c.biancheng.net/java/) 自带的原型模式基于内存二进制流的复制，在性能上比直接 new 一个对象更加优良。
- 可以使用深克隆方式保存对象的状态，使用原型模式将对象复制一份，并将其状态保存起来，简化了创建对象的过程，以便在需要的时候使用（例如恢复到历史某一状态），可辅助实现撤销操作。

#### 原型模式的缺点：

- 需要为每一个类都配置一个 clone 方法
- clone 方法位于类的内部，当对已有类进行改造的时候，需要修改代码，违背了开闭原则。
- 当实现深克隆时，需要编写较为复杂的代码，而且当对象之间存在多重嵌套引用时，为了实现深克隆，每一层对象对应的类都必须支持深克隆，实现起来会比较麻烦。因此，深克隆、浅克隆需要运用得当。

#### 原型模式的实现

![原型模式的结构图](http://c.biancheng.net/uploads/allimg/181114/3-1Q114101Fa22.gif)

由于 Java 提供了对象的 clone() 方法，所以用 Java 实现原型模式很简单。

原型模式包含以下主要角色。

1. 抽象原型类：规定了具体原型对象必须实现的接口。
2. 具体原型类：实现抽象原型类的 clone() 方法，它是可被复制的对象。
3. 访问类：使用具体原型类中的 clone() 方法来复制新的对象。

```java
//具体原型类
class Realizetype implements Cloneable {
    Realizetype() {
        System.out.println("具体原型创建成功！");
    }
    public Object clone() throws CloneNotSupportedException {
        System.out.println("具体原型复制成功！");
        return (Realizetype) super.clone(); // 浅拷贝
    }
}
//原型模式的测试类
public class PrototypeTest {
    public static void main(String[] args) throws CloneNotSupportedException {
        Realizetype obj1 = new Realizetype();
        Realizetype obj2 = (Realizetype) obj1.clone();
        System.out.println("obj1==obj2?" + (obj1 == obj2));
    }
}
```



[Java中的深浅拷贝（clone）](https://www.cnblogs.com/xzwblog/p/7230788.html)





## 列举Java几个异常

1. ` java.lang.OutOfMemoryError`
   - 当可用内存不足以让Java虚拟机分配给一个对象时抛出该错误。
2. ` java.lang.StackOverflowError`
   - 当一个应用递归调用的层次太深而导致堆栈溢出或者陷入死循环时抛出该错误
3. `java.lang.CloneNotSupportedException`
   - clone方法所在类没有继承Cloneable接口
4. `java.util.ConcurrentModificationException` 





# Linux 复习

## 常用命令

```bash
# 查看磁盘情况
df -h 

# 查看目录，或文件使用磁盘情况
du

# 查看内存使用情况
free -h

# http 工具

curl URL

# 进程
ps -ef

top

htop 交互式top命令


# 远程同步
scp

rsync   # 同步，同步之间会比较之前的文件，只会同步更改的内容


# 比较两个文件的差异
diff 文件1 文件2 -y -W

# 查看历史命令
history


# 服务管理命令

service

# 管理systemd的资源Unit
systemctl





```



### top详解

```shell
# 当前时间、系统已运行时间、当前登录用户的数量、最近5、10、15分钟内的平均负载
# load average数据是每隔5秒钟检查一次活跃的进程数，然后按特定算法计算出的数值。如果这个数除以逻辑CPU的数量，结果高于5的时候就表明系统在超负荷运转了
top - 15:56:34 up 46 days, 20:13,  0 users,  load average: 8.20, 9.77, 10.36
# tasks 统计，系统现在共有34个任务，1个正在运行，33
Tasks:  34 total,   1 running,  33 sleeping,   0 stopped,   0 zombie
# CPU 使用情况 
# us：用户空间占用情况
# sy：内核空间占用情况
# ni：改变过优先级的进程占用CPU的百分比
# id：空闲CPU百分比
# wa： IO等待占用CPU的百分比
# hi：硬中断占用cpu百分比
# si：软中断占用cpu百分比
%Cpu(s):  5.2 us,  5.1 sy,  0.6 ni, 89.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
KiB Mem : 26390454+total, 18626068 free, 18532243+used, 59956032 buff/cache
KiB Swap:        0 total,        0 free,        0 used. 47536756 avail Mem 
```



# MySql复习





## 1. 数据库三范式

1. **第一范式：每个列不可再分**
2. **第二范式：不存在部分函数依赖**
3. **第三范式：不存在传递函数依赖**



## 2.MySql存储引擎

MySql中的数据，索引以及其他对象是如何存储的，是一套文件系统实现的（Storage Engine）

MY_SQL存储引擎有以下几种：

- MRG_MYISAM
- MyISM
- BLACKHOLE
- CSV
- MEMORY
- ARCHIVE
- InnoDB
- PERFORMANCE_SCHEMA



**InnoDB引擎**：InnoDB引擎提供了对数据库ACID事务的支持。并且还提供了行级锁和外键的约束。它的设计的目标就是处理大数据容量的数据库系统。

**MyISAM引擎**：不提供事务的支持，也不支持行级锁和外键

**Memory引擎**：所有的数据都在内存中，数据的处理速度快，但是安全性不搞。



**常见的*MyISAM*与*InnoDB*的比较**

|                                                              | MyISAM                                                       | InnoDB                                                       |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 存储结构                                                     | 每张表被存放在三个文件：<br />frm-表格定义<br />MYD（MYData）-数据文件<br />MYI（MYIndex）-索引文件 | 所有的表都保存在同一个数据文件中<br />（也可能是多个文件，或者是独立的表空间文件）<br />InnoDB表的大小只受限于操作系统文件的大小，<br />一般为2GB |
| 存储空间                                                     | MyISAM可被压缩，存储空间较小                                 | InnoDB的表需要更多的内存和存储，<br />它会在主内存中建立专用的缓冲池<br />用于高速缓冲数据和索引 |
| 可移植性、备份及恢复                                         | 由于MyISAM的数据是以文件的形式存储，所以在跨平台的数据转移中会很方便。<br />在备份和恢复时可单独针对某个表进行操作。 | 数据和索引都是集中存储的                                     |
| 记录存储顺序                                                 | 按记录插入顺序保存                                           | 按主键大小有序插入                                           |
| 外键                                                         | **不支持**                                                   | **支持**                                                     |
| 事务                                                         | **不支持**                                                   | **支持**                                                     |
| 锁支持（锁是避免资源争用的一个机制，MySql锁对用户几乎是透明的） | **表级锁定**                                                 | **行级锁定**，**表级锁定**，锁定粒度小并发能力高             |
| SELECT                                                       | MyIsam更有                                                   |                                                              |
| INSERT、UPDATE、DELETE                                       |                                                              | InnoDB更优                                                   |
| 索引的实现方式                                               | B+树索引，myisam是堆表                                       | B+树索引，InnoDB是索引组织表                                 |
| 哈希索引                                                     | 不支持                                                       | 支持                                                         |
| 全文索引                                                     | 支持                                                         | 不支持                                                       |

**MyISAM索引与InnoDB索引的区别**

- InnoDB索引是聚簇索引（索引的存储顺序与实际的数据物理存储顺序保持一致），MyIsam索引是非聚簇索引
- InnoDB的主键索引的叶子结点存储着行数据，因此主键索引非常高效
- MyISAM索引的叶子结点存储的是行数据地址，需要再寻址一次才能得到数据
- InnoDB非主键索引的叶子结点存储的是主键和其他索引的列数据，因此查询时做到覆盖索引会非常高效。





## 3. 索引

### 3.1 什么是索引？

索引是一种数据结构。数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据。索引的实现通常使用B树及其变种B+树。

### 3.2 索引的优点

- 可以大大加快数据的检索速度，这就是创建索引的最主要的原因
- 通过使用索引，可以在查询的过程中，使用优化器，提高系统的性能

### 3.3 索引的缺点

- 时间方面：创建索引和维护索引要耗费时间，具体地，当对表中的数据进行增加，删除和修改的时候，索引也要动态的维护，会降低增删改的执行效率。
- 空间方面：索引需要占物理空间



### 3.4 索引使用注意事项

索引虽好，但是索引使用不恰当就会造成索引失效

**索引使用口诀：**

1. **全值匹配我最爱**
   - 就是查询的列都是索引（覆盖索引，这中情况不需要查询实际的物理数据，只需要查询索引树即可）
2. **最佳左前缀法则**
   - 如果索引了多列，在使用时就要遵守最左前缀法则
     - 带头大哥不能死
     - 中间兄弟不能断
3. **索引列上不计算**
   - 使用sum，avg等计算或者 自动(手动)类型转换，都会导致索引失效
4. **范围之后全失效**
5. **%加在like右边**
6. **字符串里有引号**
   - 字符转不加单引号，会导致索引失效
7. 其他
   - 使用**!=，<>, is null； is not null ；or**都会导致索引失效



**非聚簇索引一定会产生回表吗？**

不一定。如果查询语句中的的列全部命中索引，那就不必再进行回表查询了。



## 4. MySql日志

MariaDB/MySql中日志包括：

1. 错误日志（Error log）：记录mysql服务启动时正确和错误的信息，还记录启动、停止、运行过程中的错误信息
2. 查询日志（general log）：记录建立的客户端连接和执行的语句。
3. 二进制日志（binlog）：记录所有更改数据的语句，可用于数据复制
4. 慢查询日志（show log）：记录所有执行时间超过long_query_time的所有查询或不使用索引的查询
5. 中继日志（relay log）：主从复制时使用的日志。
6. InnoDB引擎还有事务日志



### 4.1 二进制日志

[事务日志详解](https://www.cnblogs.com/f-ck-need-u/archive/2018/05/08/9010872.html)

MySql支持statement、row、mixed三种形式的记录方式。

- statement
  - 将所有的相关操作记录为SQL语句的形式
  - 这样的记录方式对某些特殊信息无法同步记录，例如uuid，now()等这样的动态变化的值。
- row
  - 基于行来记录，将相关行的每一列的值都在日志中保存下来
  - 这样的结果会导致日志文件变得非常大，但是保证了动态值的确定性。
- mixed
  - statement与row混合形式
  - 默认采用statement的方式记录，只有以下几种情况会采用row的形式来记录日志
    - 表的存储引擎为NDB，这是对表的DML操作都会以row的格式记录
    - 使用了uuid(), user(), current_user(), found_rows(), row_cuount()等不确定函数。但是测试发现对now()函数仍然会以statement格式记录，而sysdate()函数会以row格式记录。
    - 使用了insert delay语句
    - 使用了临时表



### 4.2 事务日志

InnoDB存储引擎的事务日志包括：undo log 和 redo log

redo log 通常是物理日志，记录的是数据页的物理页修改，而不是某一行或某几行修改成怎么样，它用来恢复提交后的物理数据页（恢复数据页，且只能恢复到最后一次提交的位置）

undo用来回滚行记录到某个版本。undo log一般是逻辑日志，根据每行记录进行记录。

#### 1. redo log

redo log不是二进制日志。虽然二进制日志也记录了innodb表的很多操作，也能实现重做的功能，但是他们之间有很大区别。

1. 二进制日志是在**存储引擎的上层**产生的，不管是什么存储引擎，对数据库进行了修改都会产生二进制日志。而redo log是innodb层产生的，只记录该存储引擎中表的修改。**并且二进制日志先于redo log被记录**。具体的见后文group commit小结。
2. 二进制日志记录操作的方法是逻辑性的语句。即便它是基于行格式的记录方式，其本质也还是逻辑的SQL设置，如该行记录的每列的值是多少。而redo log是在物理格式上的日志，它记录的是数据库中每个页的修改。
3. 二进制日志只在每次事务提交的时候一次性写入缓存中的日志"文件"(对于非事务表的操作，则是每次执行语句成功后就直接写入)。而redo log在数据准备修改前写入缓存中的redo log中，然后才对缓存中的数据执行修改操作；而且保证在发出事务提交指令时，先向缓存中的redo log写入日志，写入完成后才执行提交动作。
4. 因为二进制日志只在提交的时候一次性写入，所以二进制日志中的记录方式和提交顺序有关，且一次提交对应一次记录。而redo log中是记录的物理页的修改，redo log文件中同一个事务可能多次记录，最后一个提交的事务记录会覆盖所有未提交的事务记录。例如事务T1，可能在redo log中记录了 T1-1,T1-2,T1-3，T1* 共4个操作，其中 T1* 表示最后提交时的日志记录，所以对应的数据页最终状态是 T1* 对应的操作结果。而且redo log是并发写入的，不同事务之间的不同版本的记录会穿插写入到redo log文件中，例如可能redo log的记录方式如下：` T1-1,T1-2,T2-1,T2-2,T2*,T1-3,T1* `。
5. 事务日志记录的是物理页的情况，它具有幂等性，因此记录日志的方式极其简练。幂等性的意思是多次操作前后状态是一样的，例如新插入一行后又删除该行，前后状态没有变化。而二进制日志记录的是所有影响数据的操作，记录的内容较多。例如插入一行记录一次，删除该行又记录一次。

**Redo log的基本概念**

redo log包括两部分：一是内存中的日志缓冲(redo log buffer)，该部分日志是易失性的；二是磁盘上的重做日志文件(redo log file)，该部分日志是持久的。

在概念上，innodb通过***force log at commit\***机制实现事务的持久性，即在事务提交的时候，必须先将该事务的所有事务日志写入到磁盘上的redo log file和undo log file中进行持久化。

为了确保每次日志都能写入到事务日志文件中，在每次将log buffer中的日志写入日志文件的过程中都会调用一次操作系统的fsync操作(即fsync()系统调用)。因为MariaDB/MySQL是工作在用户空间的，MariaDB/MySQL的log buffer处于用户空间的内存中。要写入到磁盘上的log file中(redo:ib_logfileN文件,undo:share tablespace或.ibd文件)，中间还要经过操作系统内核空间的os buffer，调用fsync()的作用就是将OS buffer中的日志刷到磁盘上的log file中。



**redo log的格式**

因为InnoDB存储引擎数据的单元是页，所以redo log也是基于页的格式来记录的。InnoDB的页大小是16kb，一个页可以存放非常多的log blcok（512字节），而log block中记录的有时数据页的变化。



**InnoDB的恢复行为**

在启动InnoDB的时候，不管上次是正常关闭还是异常关闭，总是会进行恢复操作。

因为redo log记录的是数据页的物理变化，因此恢复的时候速度比逻辑日志（比如binlog）要快很多。而且，InnoDB自身也做了一定程度的优化，让恢复速度变得更快。



#### 2. undo log

undo log有两个作用：提供回滚和多个行版本控制（MVCC）

在数据修改的时候，不仅记录了redo，还记录了相应的undo，如果因为某些原因导致事务失败或回滚，可以借助该undo进行回滚。

undo log 和 redo log记录物理日志不一样，它是逻辑日志。<font color=red>可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录。</font>

当执行rollback时，就可以从undo log中的逻辑读取到相应的内容并进行回滚。有时候应用到行版本控制的时候，也是通过undo log来实现的：当读取的某一行被其他事务锁定时，它可以从undo log中分析出该行记录以前的数据是什么，从而提供该行版本信息，让用户实现非锁定一致性读取。

<font color=red>undo log 是采用段（segment）的方式来记录的，每个undo操作在记录的时候占用一个undo log segment。</font>

另外，undo log也会产生redo log，因为undo log也要实现持久性保护。

**undo log 的存储方式**

InnoDB存储引擎对undo 的管理采用段的方式。rollback segment称为回滚段，每个混滚段中有1024个undo log segment。



另一篇帖子中的介绍：http://www.llbiancheng.com/5623.html

**Undo**：意为取消，以撤销操作为目的，返回指定某个状态的操作。

**Undo Log**：数据库事务提交之前，会将事务修改数据的镜像（即修改前的旧版本）存放到 undo 日志里，当事务回滚时，或者数据库奔溃时，可以利用 undo 日志，即旧版本数据，撤销未提交事务对数据库产生的影响。。

- 对于 insert 操作，undo 日志记录新数据的 PK(ROW_ID)，回滚时直接删除；
- 对于 delete/update 操作，undo 日志记录旧数据 row，回滚时直接恢复；
- 他们分别存放在不同的buffer里。

**Undo Log 是为了实现事务的原子性而出现的产物。**

**Undo Log 实现事务原子性**：事务处理过程中，如果出现了错误或者用户执行了 ROLLBACK 语句，MySQL 可以利用 Undo Log 中的备份将数据恢复到事务开始之前的状态。

InnoDB 发现可以基于 Undo Log 来实现多版本并发控制。

**Undo Log 在 MySQL InnoDB 存储引擎中用来实现多版本并发控制。**

**Undo Log 实现多版本并发控制**：事务未提交之前，Undo Log 保存了未提交之前的版本数据，Undo Log 中的数据可作为数据旧版本快照供其他并发事务进行快照读。

关于Undo log是怎么实现MVCC的，请参考上篇文章：[吃透MySQL（九）：MVCC多版本并发控制](https://blog.csdn.net/u013277209/article/details/114360409)



**Redo**：顾名思义就是重做。以恢复操作为目的，重现操作。

**Redo Log**：指事务中操作的任何数据，将最新的数据备份到一个地方（Redo Log）。

**Redo Log 的持久化**：不是随着事务的提交才写入的，而是在事务的执行过程中，便开始写入 Redo Log 中，具体的落盘策略可以进行配置。

**Redo Log 是为了实现事务的持久性而出现的产物。**

**Redo Log 实现事务持久性**：防止在发生故障的时间点，缓冲池（buffer pool）尚有脏页未写入表的 IBD 文件中，在重启 MySQL 服务的时候，根据 Redo Log 进行重做，从而达到事务的未入磁盘数据进行持久化这一特性。

一旦事务成功提交且数据从缓冲池（buffer pool）持久化到表的 IBD 文件中之后，此时 Redo Log 中的对应事务数据记录就失去了意义，所 以 Redo Log 的写入是日志文件循环写入的过程，也就是覆盖写的过程。





### 4. 事务

#### 4.1 什么是事务？

事务是一个不可分割的数据库操作序列，也是数据库并发控制的基本单位，其执行的结果必须使数据库从一种一致性状态变到另一种一致性状态。事务是逻辑上的一组操作，要么都执行，要么都不执行。

#### 4.2 事务的四大特性（ACID）

- **原子性**（Atomicity）
- **一致性**（Consistency）
- **隔离性**（Isolation）
- **持久性**（Durability）



[参考文章](https://www.cnblogs.com/kismetv/p/10331633.html)

##### 4.2.1 原子性

原子性是指一个事务是一个不可分割的工作单位，其中的操作要么都做，要么都不做；如果事务中一个sql语句执行失败，则已执行的语句也必须回滚，数据库退回到事务前的状态。

- 实现原理：undo log

##### 4.2.2 持久性

持久性是指事务一旦提交，它对数据库的改变就应该是永久性的。就下来的其他操作或故障不应该对其有任何影响。

- 实现原理：redo log

##### 4.2.3 隔离性

与原子性、持久性侧重于研究事务本身有所不同，隔离性研究的是不同事务之间的相互影响。隔离性是指，事务内部的操作与其他事务是隔离的，并发执行的各个事务之间不能互相干扰。

隔离性追求的是并发情形下事务之间互不干扰。

隔离性探讨的问题主要分为两方面：

- （一个事务）写操作对（另一个事务）写操作的影响：锁机制保证隔离性
- （一个事务）写操作对（另一个事务）读操作的影响：MVCC保证隔离性

首先来看两个事务的写操作之间的相互影响。隔离性要求同一时刻只能有一个事务对数据进行写操作，InnoDB通过锁机制来保证这一点。

锁机制的基本原理可以概括为：事务在修改数据之前，需要先获得相应的锁；获得锁之后，事务便可以修改数据；该事务操作期间，这部分数据是锁定的，其他事务如果需要修改数据，需要等待当前事务提交或回滚后释放锁。

**行锁与表锁**

按照粒度，锁可以分为表锁、行锁以及其他位于二者之间的锁。表锁在操作数据时会锁定整张表，并发性能较差；行锁则只锁定需要操作的数据，并发性能好。但是由于加锁本身需要消耗资源(获得锁、检查锁、释放锁等都需要消耗资源)，因此在锁定数据较多情况下使用表锁可以节省大量资源。MySQL中不同的存储引擎支持的锁是不一样的，例如MyIsam只支持表锁，而InnoDB同时支持表锁和行锁，且出于性能考虑，绝大多数情况下使用的都是行锁。



**脏读、不可重复读和幻读**



并发情况下，读操作可能存在的三类问题：

1. 脏读：当前事务A可以读到其他事务B未提交的数据（脏数据），这种现象为脏读

   > ![img](https://img2018.cnblogs.com/blog/1174710/201901/1174710-20190128201003630-2050662608.png)
   >
   > 

2. 不可重复读：在事务A中先后两次读取同一个数据，两次读取的结果不一样，这种现象称为不可重复读。

   - 脏读与不可重复读的区别在于：前者读到的是其他事务未提交的数据，后者读到的是其他事务已提交的数据

   > ![img](https://img2018.cnblogs.com/blog/1174710/201901/1174710-20190128201011603-1317894910.png)

3. 幻读：在事务A中按照某个条件先后两次查询数据库，两次查询结果的条数不同，这种现象称为幻读。

   - 不可重复读与幻读的区别在于：前者是数据变了，后者是数据的行变了

   > ![img](https://img2018.cnblogs.com/blog/1174710/201901/1174710-20190128201021606-1089980279.png)

**事务的隔离级别**

SQL标准中定义了四种隔离级别，并规定了每种隔离级别下上述几个问题是否存在。一般来说，隔离级别越低，系统开销越低，可支持的并发越高，但隔离性也越差。隔离级别与读问题的关系如下：

![img](https://img2018.cnblogs.com/blog/1174710/201901/1174710-20190128201034603-681355962.png)

- Read UnCommitted 读取未提交内容
  - 在这个隔离级别，所有事务都可以“看到”为提交事务的执行结果。（会造成脏读、不可重复读、幻读）
- Read Committed 读取提交内容
  - 一个事务从开始到提交前，所做的任何数据改变都是不可见的，除非已经提交了。（解决了脏读，但是没有解决不可重复读  和 幻读）
- Repeatable Read 可重复读
  - MySql数据库默认的隔离级别
  - 它保证同一事务的多个实例在并发读取事务时，会“看到同样的”数据行。（解决了 脏读 和 不可重复读，但是没有解决  幻读）
- Serializable 可串行化
  - 该级别是最高级别的隔离级。它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简而言之，SERIALIZABLE是在每个读的数据行上加锁。在这个级别，可能导致大量的超时`Timeout`和锁竞争`Lock Contention`现象，实际应用中很少使用到这个级别，但如果用户的应用为了数据的稳定性，需要强制减少并发的话，也可以选择这种隔离级



**MVCC多版本并发控制**

MVCC可以解决幻读

<font color=green>InnoDB的MVCC实现机制</font>

- InnoDB的MVCC实现，是通过保存数据在某个时间点的快照实现的。
- 一个事务，不管其执行多长时间，其内部看到的数据是一致的。事务在执行过程中不会相互影响

MySql中，每条实际的行数据除了我们定义的字段外，还有几个隐藏的列，其中有关于MVCC的重要字段有两个：**DATA_TRX_ID**和**DELETE_BIT**

- DATA_TRX_ID 标记了最新更新这条行记录的transaction id，每处理一个事务，其值自动+1

- DELETE_BIT 用于标识该记录是否被删除，这里的不是真正的删除数据，而是标志出来的删除。真正意义的删除是在commit的时候。



下面分别以select、delete、insert、update语句来说明：

- **INSERT**
  - InnoDB为每个新增行记录当前系统版本号（事务ID）作为创建ID（DATA_TRX_ID）
- **DELETE**
  - InnoDB为每个删除行记录当前系统版本号（事务ID）作为删除ID（DELETE_BIT）
- **UPDATE**
  - InnoDB复制了一行。这个新行的版本号使用了系统版本号。它也把系统版本号作为了删除行的版本。
- **SELECT**
  - InnoDB检查每行数据，确保他们符合两个标准
    - InnoDB只查找早于当前事务版本的数据行（也就是数据行的版本必须小于等于事务的版本），这确保当前事务读取的行都是事务之前已经存才的，或者是由当前事务创建或修改的行。
    - 行的删除操作的版本一定是未定义的或者大于当前事务版本号，确定了当前事务开始之前，行没有被删除
  - 符合了以上两点则返回查询结果

InnoDB中的MVCC实现方式：

- 事务以排它锁的形式修改原始数据
- 把修改前的数据存放于undo log，通过回滚指针与主数据关联
- 修改成功（commit）啥都不做，失败则恢复undo log中的数据（rollback）



二者最本质的区别是，当修改数据时是否要排他锁定，如果锁定了还算不算是MVCC？ 

 

Innodb的实现真算不上MVCC，因为并没有实现核心的多版本共存，undo log中的内容只是串行化的结果，记录了多个事务的过程，不属于多版本共存。但理想的MVCC是难以实现的，当事务仅修改一行记录使用理想的MVCC模式是没有问题的，可以通过比较版本号进行回滚；但当事务影响到多行数据时，理想的MVCC据无能为力了。

 

比如，如果Transaciton1执行理想的MVCC，修改Row1成功，而修改Row2失败，此时需要回滚Row1，但因为Row1没有被锁定，其数据可能又被Transaction2所修改，如果此时回滚Row1的内容，则会破坏Transaction2的修改结果，导致Transaction2违反ACID。

 

理想MVCC难以实现的根本原因在于企图通过乐观锁代替二段提交。修改两行数据，但为了保证其一致性，与修改两个分布式系统中的数据并无区别，而二提交是目前这种场景保证一致性的唯一手段。二段提交的本质是锁定，乐观锁的本质是消除锁定，二者矛盾，故理想的MVCC难以真正在实际中被应用，Innodb只是借了MVCC这个名字，提供了读的非阻塞而已。



##### 4.2.4 一致性

一致性是指事务执行结束后，**数据库的完整性约束没有被破坏，事务执行的前后都是合法的数据状态**。数据库的完整性约束包括但不限于：实体完整性（比如行的主键存在且唯一）、列完整性（如字段的类型，大小，长度要符合要求）、外键约束、用户自定义完整性。

可以说，一致性是事务追求的最终目标：前面提到的原子性，持久性和隔离性，都是为了保证数据库状态的一致性。此外，除了数据库层面的保障，一致性的实现也需要应用层面进行保障。



实现一致性的措施：

- 保证原子性、持久性和隔离，如果这些特性无法保证，事务的一致性也无法保证。
- 数据库本身提供保障，例如不允许向整型列插入字符串值，字符串长度不能超过列的限制等
- 应用层面进行保障，例如如果转账操作只扣除转账者的余额，而没有增加接受者的余额，无论数据库实现的多么完美，也无法保证状态的一致性。

​			



















## 5. 锁

MySQL里面的锁大致可以分成 **全局锁**、**表级锁**和**行级锁**这三类。

### 全局锁

全局锁就是对整个数据库实例加锁。

**全局锁的典型使用场景：做全库逻辑备份**，也就是把整库每个表都select出来存成文本。

但是全局锁会导致整个库进入只读状态，在实际的线上任务中，这很危险。



### 表级锁

Mysql中的表级别的锁有两种：

- 表锁

  - MyISAM引擎
    - **表共享读锁**
      - 不会阻塞其他线程对同一个表的读操作请求，但会阻塞其他线程的写操作请求；
    - **表独占写锁**
      - 一旦表被加上独占写锁，那么无论其他线程是读操作还是写操作，都会被阻塞。

  默认情况下，写锁比读锁具有更高的优先级；当一个锁释放后，那么它会优先相应写锁等待队列中的请求，然后再是读锁中等待的获取锁的请求。

  - InnoDB引擎
    - 表锁---------**-意向锁**
      - 由于表锁和行锁虽然作用范围不同，但是会相互冲突。当你要加表锁时，势必要先遍历表的所有记录，判断是否有**排它锁**。这种遍历检查的方式显然是一种低效的方式。InnoDB引入了**意向锁**，来检测表锁和行锁的冲突。
      - 意向锁也是表级锁，分为**读意向锁(IS)**，和**写意向锁(IX)**。当事务要在记录上加行锁时，要首先在表上加意向锁。这样判断表中是否有记录正在加锁就很简单了，只要看下表上是否有意向锁就行了。从而就能提升效率。
      - 意向锁之间不会产生冲突，它只会阻塞表级读锁或写锁。意向锁不与行锁发生冲突。

- 元数据锁（MDL）

  - 元数据锁MDL是系统默认加的
  - 当表的结构发生变化时，这个锁就会生效

> 表锁不会出现死锁，发生锁的冲突几率高，并发低
>
> MyISAM在执行查询语句（select）前，会自动给涉及的所有表加读锁，在执行insert、delete和update前，会自动给涉及的表加写锁。
>
> 读锁会阻塞写，写锁会阻塞读和写
>
> - MyISAM表的读操作，不会阻塞其他线程对同一表的读请求，但会阻塞对同一表的写请求。只有当读锁释放后，才会执行其他进程的写操作。
> - 对MyISAM表的写操作，会阻塞其他进程对同一表的读和写操作，只有当写锁释放后，才会执行其他进程的读写操作。
>
> MyISAM引擎不适合做写为主表的引擎，因为写锁后，其他线程不能做任何操作，大量的更新会使查询很难得到锁，从而造成永远阻塞。





### 行锁

**InnoDB中的行锁**

InnoDB实现了一下两种类型的行锁：

- 共享锁（S）：加了锁的记录，所有事务都能去读取但不能修改，同时阻止其他事务获得相同数据集的排它锁
- 排它锁（X）：允许已经获得排它锁的事务去更新数据，阻止其他事务获得相同数据集的共享锁和排它锁。

**锁模式的兼容矩阵**

下面表显示了了各种锁之间的兼容情况：

|      | X    | IX   | S    | IS   |
| ---- | ---- | ---- | ---- | ---- |
| X    |      |      |      |      |
| IX   |      | 兼容 |      | 兼容 |
| S    |      |      | 兼容 | 兼容 |
| IS   |      | 兼容 | 兼容 | 兼容 |

（注意上面的X与S是说表级的X锁和S锁，意向锁不和行级锁发生冲突）

如果一个事务请求的锁模式与当前的锁兼容，InnoDB就将请求的锁授予该事务；如果两者不兼容，那么该事务就需要等待锁的释放。



<font color=red>注意：</font>

<font color=green>InnoDB的行锁是作用在索引上的，哪怕建表的时候没有定义一个索引，InnoDB也会创建一个聚簇索引并将其作为锁作用的索引。</font>

<font color=green>行锁必须有索引才能实现，否则会自动锁全表。</font>

- 两个事务不能锁同一个索引
- insert，delete，update在事务中都会自动默认加上排它锁

## 6. 性能分析与优化

### Exlain查询执行计划

```sql
explain select 
								id
								,name
								,addr
				from		t1
        where		t1.id = 20
```

通过在sql前面添加explain关键字即可查询sql的执行计划

![img](https://gimg2.baidu.com/image_search/src=http%3A%2F%2Faliyunzixunbucket.oss-cn-beijing.aliyuncs.com%2Fjpg%2F6dd68b173df7809bc8dc27a30937a22d.jpg%3Fx-oss-process%3Dimage%2Fresize%2Cp_100%2Fauto-orient%2C1%2Fquality%2Cq_90%2Fformat%2Cjpg%2Fwatermark%2Cimage_eXVuY2VzaGk%3D%2Ct_100&refer=http%3A%2F%2Faliyunzixunbucket.oss-cn-beijing.aliyuncs.com&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=jpeg?sec=1630634532&t=cc5ce4c5d99be9f2529373c3cd481029)

如上图，sql的执行计划共有10个字段

1. **id**

   > 表的查询顺序，需要越大表就越先被查询，相同id，表从上之下依次执行

2. **select_type**

   > 查询类型：
   >
   > **SIMPLE**：不带有任何复杂查询
   >
   > **PRIMARY**：查询中若包含任何复杂的子部分，最外层查询则被标记为PRIMARY
   >
   > **SUBQUERY**：在select或where列表中包含了子查询
   >
   > **DERIVED**衍生：在from列表中包含的子查询标记为DERIVEN（MySql会递归执行这些子查询，把结果放在临时表里）
   >
   > **UNION**：若第二个select出现在union之后，则被标记为UNION
   >
   > ​				若UNION包含在from子句的子查询中，外层select将被标记为：DERIVED
   >
   > **UNION RESULT**：从UNION表获取结果的select

3. **table**

   - 显示这一行数据是关于哪张表的

4. **type**

   > **查询的访问类型**
   >
   > 常见的访问类型：system--const--eq_ref--ref--range--index--ALL
   >
   > 1. **System**:表中只有一行记录，这是const类型的特例
   > 2. **const**：表示通过索引一次就找到了，const用于比较primary key 或者unique索引，因为只匹配一行数据，所以很快
   > 3. **eq_ref**：唯一性索引扫描，对于每个索引键，表中只用一条记录与之匹配。常见于主键或唯一性索引
   > 4. **ref**：非唯一性索引扫描，返回匹配某个单独值的所有行，本质上也是一种索引访问。
   > 5. **range**：指索引给定范围的行，使用一个索引来选择行；between、<、>和in等的查询
   > 6. **index**：出现index是sql使用了索引但是没有通过索引进行过滤，一般是使用了覆盖索引或者利用索引进行排序，分组等。
   > 7. **ALL**：全表扫描
   >
   > index 与 ALL的区别：都是全表扫描，但是index遍历的只有索引树，而ALL是从硬盘中读取全部的表数据，前者的速度要快于后者。

   一般情况下，查询至少达到range级别，最好达到ref级别

   5. **possible_keys**

      > 显示可能应用在这张表中的索引，一个或者多个
      >
      > 查询涉及到的字段若存在索引，该索引将被列出
      >
      > **但是不一定被查询实际使用**

   6. **key**

      > 实际使用的索引。如果为NULL，则没有使用索引
      >
      > 查询中若使用了覆盖索引，则该索引仅出现在key列表中

   7. **key_len**

      > 表示索引中使用的字节数，通过该列计算查询中使用的索引长度，在不损失精确性的情况下，长度越短越好。
      >
      > key_len显示的值为索引字段的最大可能长度，并非实际使用长度，即key_len是根据表定义计算而得，不是通过表内检索出的。

   8. **ref**

      > 显示索引的哪一列被使用了，如果可能的话，是一个常数，哪些列或常量被用于查找索引列上的值

   9. **rows**

      > 根据表统计信息即索引选取情况，大致估算出找到所需的记录所需要读取的行数

   10. **Extra**

       1. **using filesort**
          - 说明mysql会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取
          - mysql中无法利用索引完成的排序操作称为：“文件排序”
       2. **using temporary**
          - 使用了临时表保存中间结果，mysql在对查询结果排序时，使用临时表。常见于排序order by和分组查询group by
       3. **using index**
          - using index表示相应的select操作中使用了覆盖索引，避免访问了表的数据行，效率不错！
          - 如果同时出现using where，表名索引被用来执行索引键值的查找；如果没有同时出现using where，表名索引只是用来读取数据而非利用索引执行查找
          - 利用索引进行了排序或者查找
       4. **using where**
       5. **using join buffer**









## 7. Mysql主从复制 & 集群



### 7.1 MySql主从复制

[docker 搭建mysql主从复制](https://blog.csdn.net/weixin_44617722/article/details/111996883)

[mysql授权用户](https://www.cnblogs.com/felix-h/p/11072743.html)

MySQL主从复制是指数据可以从一个MySQL数据库服务器主节点复制到一个或多个从节点。

MySQL主从复制默认采用异步复制方式，这样从节点不用一直访问主服务器来更新自己的数据，数据的更新可以在远程连接上进行，从节点可以复制主数据库中的所有数据库或者特定的数据，或者特定的表。

**Mysql主从复制原理**

1. master服务器将数据的改变记录到二进制日志binlog日志，当master上的数据发生改变时，则将其改变写入二进制日志中；
2. slave服务器会在一定时间间隔内对master二进制日志进行探测其是否发生改变，如果发生改变，则开始一个I/O Thread请求master二进制事件。
3. 同时主节点为每个I/O线程启动一个dump线程，用于向其发送二进制事件，并保存至从节点本地的**中继日志中（relay log）**，从节点将启动SQL线程从中继日志中读取二进制日志，在本地重放，似的其数据和主节点的保持一致，最后I/O Thread和SQL Thread将进入睡眠，等待下一下被唤醒。



- 从库会生成两个线程：一个I/O线程，一个SQL线程
- I/O线程会去请求主库的binlog，并将得到的binlog写到本地的relay-log（中继日志）文件中
- 主库会生成一个log dump线程，用来给从库I/O线程传binlog；
- SQL线程会读取relay log文件中的日志，并解析成sql语句逐一执行；

**注意**

1. master将操作语句记录到binlog日志中，然后授予slave远程连接的权限（master一定要开启binlog二进制日志功能；通常为了数据安全考虑，slave也开启binlog功能）。
2. slave开启两个线程：IO线程和SQL线程。其中：IO线程负责读取master的binlog内容到中继日志relay log里；SQL线程负责从relay log日志里读出binlog内容，并更新到slave的数据库里，这样就能保证slave数据和master数据保持一致了。 
3. Mysql复制至少需要两个Mysql的服务，当然Mysql服务可以分布在不同的服务器上，也可以在一台服务器上启动多个服务。
4. Mysql复制最好确保master和slave服务器上的Mysql版本相同（如果不能满足版本一致，那么要保证master主节点的版本低于slave从节点的版本）
5. master和slave两节点间时间需同步

![img](https://pic3.zhimg.com/80/v2-cf37bafd8a121454b5488c53ff2e0b2e_1440w.jpg)

具体细节

1. 从库通过手工执行change master to 语句连接主库，提供了连接的用户一切条件（user 、password、port、ip），并且让从库知道，二进制日志的起点位置（file名 position 号）； start slave
2. 从库的IO线程和主库的dump线程建立连接。
3. 从库根据change master to 语句提供的file名和position号，IO线程向主库发起binlog的请求。
4. 主库dump线程根据从库的请求，将本地binlog以events的方式发给从库IO线程。
5. 从库IO线程接收binlog events，并存放到本地relay-log中，传送过来的信息，会记录到[master.info](https://link.zhihu.com/?target=http%3A//master.info)中
6. 从库SQL线程应用relay-log，并且把应用过的记录到[relay-log.info](https://link.zhihu.com/?target=http%3A//relay-log.info)中，默认情况下，已经应用过的relay 会自动被清理purge

**主从复制优缺点**

- 读写分离：一主多从，主写，从读，分散压力。
- 缺点
  - 数据库服务存在单点故障（主库所在机器可能宕机）
  - 数据库服务器资源无法满足增长的读写请求
  - 高峰时数据库连接数经常超过上线
  - 同步机制为**异步**

### 7.2 Mysql集群





















## 8. 补充



### 8.1 SQL的生命周期

<img src="https://github.com/xiaowodi/Resources/blob/main/images/gitImages/Mysql%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84.png?raw=true" alt="Mysql基本架构.png" style="zoom:30%;" />





1. 首先客户端向服务器提交要执行的SQL；

   客户端需要通过**连接器**连接到**Server**，并验证这个客户端的权限等

2. 连接建立完成后，就可以执行sql，执行逻辑的第二步就是要**查询缓存**，如果缓存中有之前查询的结果，就直接返回给客户端。（缓存中类似于Key-Value的形式）

3. 如果缓存没有命中，接下来就需要**分析器**，经过*词法分析*，*语法分析*，来分析这个sql语句是否符合sql语法规范。

4. 对于可以执行的sql要经过**优化器**进行优化

5. 优化后的sql就会到**执行器**中，执行这个sql逻辑

   - 开始执行的时候，要先判断一下客户端对这个表有没有执行查询的权限，如果没有，就会返回权限错误。
   - 如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。













# Hadoop复习



## 1. 分布式文件存储系统HDFS

### 1.1 HDFS的机架感知策略

- 机架：存放服务器的架子，也叫机柜。一般来说一个机房有很多机柜，每个机柜有很多服务器

**副本存放策略**

HDFS分布式文件系统的内部有一个副本存放策略：以默认的副本数=3为例：

1. 第一个副本块存本机
2. 第二个副本块存放在跟本机同机架内的其他服务器节点
3. 第三个副本块存放在不同于本机架的一个服务器节点上

==好处：==

1. 如果本机数据损坏或者丢失，那么客户端可以从同机架的相邻节点获取数据，速度肯定要比跨机架获取数据要快。
2. 如果本机所在的机架出现问题，那么之前在存储的时候没有把所有副本都放在一个机架内，这就能保证数据的安全性，此种情况出现，就能保证客户端也能取到数据。

HDFS为了降低整体的网络带宽消耗和读取延时，HDFS集群一定会让客户端尽量去读取近的副本，那么按照以上解释的副本存放策略：

1. 如果在本机有数据，那么直接读取；
2. 如果在跟本机同机架的服务器节点中有该数据块，则直接读取
3. 如果该HDFS集群跨多个数据中心，那么客户端也一定会优先读取本数据中心的数据。

但是HDFS是如何确定两个节点是否属于同一个机架，如何确定不同服务器跟客户端的远近呢？那就是**机架感知**



### 1.2 **NameNode & DataNode & Secondary NameNode**

整个HDFS集群由Namenode和Datanode构成master-worker（主从）模式。Namenode负责构建命名空间，管理文件的元数据等，而Datanode负责实际存储数据，负责读写工作。

#### **NameNode**

NameNode存放文件系统树以及所有文件、目录的元数据。

元数据持久化为2种形式：

- namespace image
- edit log

在HDFS中，Namenode可能成为集群的单点故障，Namenode不可用时，整个文件系统是不可用的。HDFS针对单点故障提供了2种解决机制： 
1）**备份持久化元数据** 
将文件系统的元数据同时写到多个文件系统， 例如同时将元数据写到本地文件系统及NFS。这些备份操作都是同步的、原子的。

2）**Secondary Namenode** 
Secondary节点定期合并主Namenode的namespace image和edit log， 避免edit log过大，通过创建检查点checkpoint来合并。它会维护一个合并后的namespace image副本， 可用于在Namenode完全崩溃时恢复数据。

Secondary Namenode通常运行在另一台机器，因为合并操作需要耗费大量的CPU和内存。其数据落后于Namenode，因此当Namenode完全崩溃时，会出现数据丢失。 通常做法是拷贝NFS中的备份元数据到Second，将其作为新的主Namenode。 
在HA（High Availability高可用性）中可以运行一个Hot Standby，作为热备份，在Active Namenode故障之后，替代原有Namenode成为Active Namenode。

#### 1.3 **SecondaryNameNode工作原理**

[别扯了，Secondary NameNode工作原理就看这家](https://blog.csdn.net/u010848845/article/details/118491365)

![img](https://img-blog.csdnimg.cn/20210705153740561.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA4NDg4NDU=,size_16,color_FFFFFF,t_70)

1 ）**第一阶段： NameNode 启动**

（ 1 ）第一次启动 NameNode 格式化后，创建 Fsimage 和 Edits 文件。如果不是第一次启动，直接加载编辑日志和镜像文件到内存。
（ 2 ）客户端对元数据进行增删改的请求。
（ 3 ） NameNode 记录操作日志，更新滚动日志。
（ 4 ） NameNode 在内存中对元数据进行增删改。

2 ）**第二阶段： Secondary NameNode 工作**

（ 1 ） Secondary NameNode 询问 NameNode 是否需要 CheckPoint 。直接带回 NameNode
是否检查结果。
（ 2 ） Secondary NameNode 请求执行 CheckPoint 。
（ 3 ） NameNode 滚动正在写的 Edits 日志。
（ 4 ）将滚动前的编辑日志和镜像文件拷贝到 Secondary NameNode 。
（ 5 ） Secondary NameNode 加载编辑日志和镜像文件到内存，并合并。
（ 6 ）生成新的镜像文件 fsimage.chkpoint 。
（ 7 ）拷贝 fsimage.chkpoint 到 NameNode 。
（ 8 ） NameNode 将 fsimage.chkpoint 重新命名成 fsimage 。

### 1.4 DataNode

数据节点负责存储和提取Block，读写请求可能来自nameNode，也可能直接来自客户端。数据节点周期性向NameNode汇报自己节点上所有存储的BLock相关信息。



### 1.5 HDFS 设计目标

- 存储非常大的文件
- 采用流式的数据访问方式

**不适合的应用类型：**

- 低延时的数据访问
  - 对延时要求在毫秒级别的应用，不适合采用HDFS。
- 大量小文件
  - 文件的元数据（如目录结构，文件block的节点列表，block-node mapping）保存在NameNode的内存中，整个文件系统的文件数量会受限于NameNode的内存大小。
- 多方读写，需要任意的文件修改
  - HDFS采用追加的方法写入数据，不支持文件任意offset修改。不支持多个写入器。

### 1.6 HDFS的文件存储格式

[HDFS的文件存储格式](https://www.cnblogs.com/wqbin/p/14635480.html)

可分为**行式存储**和**列式存储**两大类。

![img](https://upload-images.jianshu.io/upload_images/6450093-0c5b3f7a2eceaaef.jpg)

#### 行式存储

同一行的数据存储在一起，即连续存储。例如：`SequenceFile`,  `MapFile`, `Avro`, `Datafile`等格式都是使用行式存储的。

如果只需要访问行的一小部分列数据，也需要将整行的数据读入内存。举个例子：一行中有十列的数据，取数的时候只需要取两列的数据，那么就需要把整个行中的所有数据都需要读取出来。

- **SequenceFile**
- **MapFile**
- **Avro**
- **DataFile**

#### 列式存储

整个文件被切割为若干列数据，每一列数据一起存储。`Parquet`, `RCFile`, `ORCFile`.面对列式存储的数据，可以跳过不需要的列，适合于只处理行的一小部分字段的情况。但是这种格式的读写需要更多的内存空间，因为需要缓存行在内存中（为了获取多行中的某一列）。

同时不适合流失写入，因为一旦写入失败，当前文件无法恢复，而面对行的数据在写入失败时，可以重新同步到最后一个同步点。

- **Parquet**
- **RCFile**
- **ORCFile**



![img](https://upload-images.jianshu.io/upload_images/6450093-dbe2595ee1e293b1.png)





一般情况下，离线处理中的宽表会有很多的字段，而在进行分析的时候，只需要一小部分字段即可，所以实际生产中，列式存储的情况比较多。



**Parquet与ORC的对比**

![image](https://imgconvert.csdnimg.cn/aHR0cHM6Ly95cWZpbGUuYWxpY2RuLmNvbS9lOGI3ODEzNzIyMGM4OTUyOGVjZDA0NDY0NjJiZDI3Y2FmNGRmNTRkLnBuZw?x-oss-process=image/format,png)

![image](https://imgconvert.csdnimg.cn/aHR0cHM6Ly95cWZpbGUuYWxpY2RuLmNvbS9iZTU0N2YxNGY3YmZhZGZlNGQyMjJkOTFhNDIyMTk4NmJkNzU3ZDk2LnBuZw?x-oss-process=image/format,png)





小总结：ORC的压缩能力强，支持ACID，支持更新，删除等操作。但是嵌套式结构实现比较复杂。



### 1.7 HDFS的读写流程

#### 1.7.1 HDFS 的 写流程

![img](https://www.pianshen.com/images/782/2d5555fa9bb1b9bda4614b97abcc7d0e.png)

客户端发起写请求到NameNode，NameNode返回可用的资源，客户端根据资源使用情况对要写如的数据分块，逐一上传块到DataNode，DataNode获取上传块数据并写入磁盘，完成后报告给NameNode块信息，同时也告诉客户端写入成功，客户端继续后续块的写入，在此期间NameNode接受到DataNode块写入完成信息之后备份数直到满。

1. 首先客户端发起写请求到NameNode，NameNode检查目录是否存在，父目录是否存在。
2. NameNode通知客户端是否可以上传
3. client长传时，先对文件进行分块，默认block为128M。client向NameNode请求第一个block需要传输到哪个DataNode上。
4. NameNode接受到请求，返回可用的DataNode。假设备份副本数为3，那么就返回三个可用的DataNode。（client同机器d1,同机架的另一台服务器的d2， 不同机架的另一台服务器的d3）
5. client请求一台DataNode建立block传输管道，第一个datanode接受到请求后会继续调用第二个datanode，然后第二个datanode调用第三个datanode，将整个pipeline建立完成，逐级返回客户端（这个过程是串联的）
6. 三个datanode逐级应答客户端。
7. 客户端开始往d1节点上传第一个block，然后上传到d2，接下来是d3
8. 当第一个block传输完后，客户端再次请求namenode上传第二个接收的block的datanode节点，直到最后一个block上传完成为止。

#### 1.7.2 HDFS 的 读流程

![img](https://www.pianshen.com/images/955/28906ddfe55a52f88180366de7c6b3bb.png)

客户端发起读请求到NameNode，NameNode返回可使用的DataNode，客户端根据返回的资源到对应的DataNode上读取块数据，客户端合并文件数据。

1. client和namenode通信查询元数据（block所在的datanode节点），找到所在的datanode服务器
2. 挑选一台datanode（就近原则，然后随机）服务器请求建立socket流
3. datanode发送数据，从磁盘读取数据放入流，以packet为单位来做校验。
4. 客户端以packet为单位接收，先在本地缓存，然后写入目标文件，最后合并文件。







## 2. 分布式计算框架MapReduce



### 2.1 MapReduce工作流程

#### 2.1.1 MapTask工作机制

![img](https://img2020.cnblogs.com/blog/1748663/202007/1748663-20200726181803473-2052825806.png)



1. MapTask收集Mapper中的map()方法每次输出的key-value值，放入到环形缓冲区中。

   环形缓冲区默认大小100M

   环形缓冲区双向写入，一侧记录索引值，一侧记录真是的数据

2. 环形缓冲区中的数据达到80%的时候，开始进行反向溢写

3. 从缓冲区溢写出来的数据会根据**分区器**进行分区，且每个分区内，会通过**快速排序**，对key排序，保证每个分区中的数据是有序的。

4. 接下来将缓冲区本次溢写出来的且分区内有序的数据落盘（多临时小文件），待数据都处理完后，多个溢出文件会被合并成大的溢出文件（这个过程通过**归并排序**，使得这个大的溢出文件内部也是有序的）。

5. 如果MapTask开启了**Combiner**预聚合功能，那么在缓冲区溢出数据分区排序完之后，每个分区内会做一次预聚合的操作，将相同key的记录按照一定的规则进行聚合，然后落盘，合并。

6. 每个MapTask所在机器上都会输出对应的Map阶段的结果。



#### 2.1.2 ReduceTask工作机制

![img](https://img2020.cnblogs.com/blog/1748663/202007/1748663-20200726181824985-212928464.png)



1. 每个**ReduceTask**从上阶段的各个MapTask所在机器上拷贝**当前ReduceTask负责的分区数据**到自己的缓冲区中（如果数据超过缓存区大小，则写到磁盘上）
2. 对于来自多个MapTask上的数据进行**归并排序**，合并成一个文件，将具有相同key的数据排列在一起，这样就实现了按照key进行分组，也可称之为局部排序
3. 每组数据经过reduce()方法进行处理
4. 最终将计算结果写到HDFS上。



### 2.2 Shuffle机制

![img](https://img2020.cnblogs.com/blog/1748663/202007/1748663-20200726181459479-554913934.png)

MapReduce整个Shuffle阶段横跨了MapTask和ReduceTask这两个任务阶段。





























## 3. 集群资源管理器Yarn

























# Spark复习















# Hive 复习















# Kafka复习

















# Flink复习















# 数仓复习



















# Zookeeper复习

































































